{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7d9f70-de4d-4b0b-a2f9-181479c04312",
   "metadata": {},
   "source": [
    "### Experiment with a local llm as judge, critic etc'\n",
    "* Need to use code from elsewhere for munging candidates into prompts\n",
    "* Open Medical-LLM Leaderboard: https://huggingface.co/spaces/openlifescienceai/open_medical_llm_leaderboard\n",
    "* Need to try diff models\n",
    "* https://www.reddit.com/r/LocalLLaMA/comments/1cec23f/llama3_based_openbiollm70b_8b_outperforms_gpt4/\n",
    "*  https://huggingface.co/aaditya/Llama3-OpenBioLLM-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3695093cbf978a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmim import CMIMFeatureSelector\n",
    "# cmim = CMIMFeatureSelector(task='classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577184d030ae0112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## https://colab.research.google.com/drive/1F5oV20InEYeAJGmBwYF9NM_QhLmjBkKJ?usp=sharing#scrollTo=fca6d8cfwOUO\n",
    "# # !CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python\n",
    "# !pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f0c7dd0-1360-40be-9b6b-5cf70409a2de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T12:07:22.836668Z",
     "start_time": "2024-10-03T12:07:22.835196Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision transformers -U\n",
    "# !pip3 install torch torchvision torchaudio transformers sentence-transformers -U\n",
    "# !conda uninstall tokenizers -y\n",
    "# !pip3 install tokenizers transformers -U\n",
    "# !pip3 install safetensors\n",
    "# !pip3 install accelerate datasets peft trl bitsnbytes -U "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93ce7cdf-13d3-48d1-8ff7-f32270f06503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T12:07:22.866329Z",
     "start_time": "2024-10-03T12:07:22.864333Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "ANNOT_DATA = \"../.././Reports/example_plausible_gallstones.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "054c0b91-2077-4ec8-be69-b443a4a96ed9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T12:07:22.881874Z",
     "start_time": "2024-10-03T12:07:22.880358Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # https://colab.research.google.com/drive/1F5oV20InEYeAJGmBwYF9NM_QhLmjBkKJ?usp=sharing#scrollTo=2xawFMf70x7F\n",
    "# from huggingface_hub import hf_hub_download\n",
    "# from llama_cpp import Llama\n",
    "# \n",
    "# model_name = \"aaditya/OpenBioLLM-Llama3-8B-GGUF\"\n",
    "# model_file = \"openbiollm-llama3-8b.Q5_K_M.gguf\"\n",
    "# \n",
    "# model_path = hf_hub_download(model_name,\n",
    "#                              filename=model_file,\n",
    "#                              # local_dir='/content\n",
    "#                              )\n",
    "# print(\"My model path: \", model_path)\n",
    "# llm = Llama(model_path=model_path,\n",
    "#             n_gpu_layers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "925a9995-e97c-42ea-919c-27d646863b62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T12:07:22.906131Z",
     "start_time": "2024-10-03T12:07:22.904543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Question = \"How can i split a 3mg or 4mg waefin pill so i can get a 2.5mg pill?\"\n",
    "# \n",
    "# #ORIG:\n",
    "# # prompt = f\"You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience. Your name is OpenBioLLM, and you were developed by Saama AI Labs with Open Life Science AI. who's willing to help answer the user's query with explanation. In your explanation, leverage your deep medical expertise such as relevant anatomical structures, physiological processes, diagnostic criteria, treatment guidelines, or other pertinent medical concepts. Use precise medical terminology while still aiming to make the explanation clear and accessible to a general audience. Medical Question: {Question} Medical Answer:\"\n",
    "# #ALT:\n",
    "# prompt = f\"\"\"You are an expert and experienced researcher from the healthcare and biomedical domain with extensive medical knowledge and practical experience. Willing to help answer the user's query with explanation. \n",
    "# In your explanation, leverage your deep medical expertise such as relevant anatomical structures, physiological processes, diagnostic criteria, treatment guidelines, or other pertinent medical concepts and scientific literature.\n",
    "# Use precise terminology while still aiming to make the explanation clear and accessible. Medical Question: {Question} Medical Answer:\"\"\"\n",
    "# \n",
    "# response = llm(prompt, max_tokens=64)['choices'][0]['text']\n",
    "# \n",
    "# print(\"\\n\\n\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4d74142b43ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"aaditya/OpenBioLLM-Llama3-8B\"\n",
    "\n",
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device=\"mps\"\n",
    "#     # \"auto\",\n",
    "# )\n",
    "\n",
    "# ## I changed prompt\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are an expert and experienced researcher from the healthcare and biomedical domain with extensive medical knowledge and practical experience. Willing to help answer the user's query with explanation. In your explanation, leverage your deep medical expertise such as relevant anatomical structures, physiological processes, diagnostic criteria, treatment guidelines, or other pertinent medical concepts and scientific literature. Use precise terminology while still aiming to make the explanation clear and accessible.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"How can i split a 3mg or 4mg waefin pill so i can get a 2.5mg pill?\"},\n",
    "# ]\n",
    "\n",
    "# prompt = pipeline.tokenizer.apply_chat_template(\n",
    "#         messages, \n",
    "#         tokenize=False, \n",
    "#         add_generation_prompt=True\n",
    "# )\n",
    "\n",
    "# terminators = [\n",
    "#     pipeline.tokenizer.eos_token_id,\n",
    "#     pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "# ]\n",
    "\n",
    "# outputs = pipeline(\n",
    "#     prompt,\n",
    "#     max_new_tokens= 64#256,\n",
    "#     ,eos_token_id=terminators,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.0\n",
    "#     ,top_p=0.9,\n",
    "# )\n",
    "# print(outputs[0][\"generated_text\"][len(prompt):])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05ab424139e5d1",
   "metadata": {},
   "source": [
    "### Load existing annotated examples and get inference on them\n",
    "* 0-shot.\n",
    "* Could use embeddings? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0fa46b817a5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ANNOT_DATA)\n",
    "## Could filter by p-values or uncommented cases\n",
    "DROP_UNCOMMENTED_EXAMPLES = False\n",
    "\n",
    "data = df.drop_duplicates(subset=df.select_dtypes([\"O\",\"bool\"]).columns)\n",
    "print(data.shape[0])\n",
    "if DROP_UNCOMMENTED_EXAMPLES:\n",
    "    data = data.loc[~data[\"COMMENTS\"].isna()].copy()\n",
    "    print(data.shape[0])\n",
    "# #Drop more cases - context limit, or for test set\n",
    "# data = data.loc[~data['COMMENTS'].str.contains(\"P val|p-val|correlation|ordinal|similar to\",case=False,na=False)]\n",
    "# print(data.shape[0])\n",
    "# # data = data.drop_duplicates(subset=['feature_name']).drop_duplicates(subset=['COMMENTS']) ## 31 -> 27\n",
    "# data = data.drop_duplicates(subset=['feature_name','COMMENTS']) ## \n",
    "print(data.shape)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc7fb435dcbbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca024fd51df9a966",
   "metadata": {},
   "source": [
    "## Load updated candidates (containing more metadata) and see if can match it to the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351cfe5286700a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_update = pd.read_csv(\"gallstone_review_interesting_candidates_results.csv\")\n",
    "# gallstone_ipw_broad_feature_report.csv\n",
    "df_update = pd.read_csv(\"../../broad_candidate_novel_cuis_chol.csv\")\n",
    "print(df_update.shape[0]) ## multiple rows per feature \n",
    "numeric_cols = df_update.select_dtypes(include='number').columns\n",
    "# df_update = df_update.drop_duplicates([\"feature_name\"])\n",
    "df_update = df_update.groupby([\"feature_name\"])[numeric_cols].max()#min()\n",
    "print(df_update.shape[0])\n",
    "df_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6430fb913cfd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_update.merge(data,on=\"feature_name\",how=\"right\", suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)').shape)\n",
    "s1 = data.shape[0]\n",
    "data = data.merge(df_update,on=\"feature_name\",how=\"left\", suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')\n",
    "assert s1 == data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43039af08973801",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Corr\")\n",
    "data.select_dtypes([\"number\",\"bool\"]).corr().round(2)[[\"Interesting?\",\"Plausible/Makes Sense?\"]].dropna(axis=0).sort_values(\"Interesting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65342331c01fe889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(data,target,get_interesting=True,get_plausible=True,print_plausible_prompt=False):\n",
    "    results = []\n",
    "\n",
    "    novel_prompts = []\n",
    "    plausible_prompts = []\n",
    "    for index, row in tqdm(data.iterrows(), total=data.shape[0], desc=\"Processing rows\"):\n",
    "        feature_name = row['feature_name']\n",
    "        target = row['Target'].replace(r\"\\(\\)\",\"\").replace(\" AND \",\" \").replace(r\"(\",\"\").replace(r\")\",\"\")\n",
    "        # target = \"Cholelithiasis OR Gallstones OR Gallbladder disease OR cholecystitis\"\n",
    "        p_val = row['p_val']\n",
    "        feature_importance = row['feature_importance']\n",
    "        correlation = row['correlation']\n",
    "        ## related to biomedical and healthcare disease understanding, prognosis, research, and prediction of:\n",
    "        prompt_interesting = f\"\"\"Given the feature '{feature_name}'; (p-value: {p_val}, correlation: {correlation}, SHAP importance {feature_importance}), as a potential predictive feature, or risk/protective factor for target disease: '{target}', is this feature Novel and interesting?\n",
    "       \\Output Yes or No prediction\"\"\" #,then explain why for a medical expert.\"\"\"\n",
    "        \n",
    "        prompt_plausible = f\"\"\"Given the feature '{feature_name}'; (p-value: {p_val}, correlation: {correlation}, SHAP importance {feature_importance}), as a potential predictive feature, or risk/protective factor for target disease:'{target}',\n",
    "        does this feature make sense? Is there a plausible mechanism for the feature to affect the target?\\\n",
    "        Output Yes or No prediction\"\"\" #, then explain for a medical expert.\n",
    "        \n",
    "        if print_plausible_prompt:\n",
    "            print(prompt_plausible)\n",
    "            print()\n",
    "\n",
    "        novel_prompts.append(prompt_interesting)\n",
    "        plausible_prompts.append(prompt_plausible)\n",
    "    \n",
    "    assert len(novel_prompts)==len(plausible_prompts) ## Doesn't check for nans or empty\n",
    "    return novel_prompts,plausible_prompts\n",
    "\n",
    "        ## following part was used for making training examples or ICL examples ofr GPT. comment out for now !\n",
    "    #     response_interesting = f\"{'Yes' if row['Interesting?'] else 'No'}. {'' if pd.isna(row['COMMENTS']) else row['COMMENTS'].strip()}\"\n",
    "\n",
    "    #     response_plausible = f\"{'Yes' if row['Plausible/Makes Sense?'] else 'No'}.\"\n",
    "    #     # # if not row['COMMENTS'].str.contains(\"P value|correlation\",case=False,na=False):\n",
    "    #     # if not row['COMMENTS'].contains(\"P value|correlation\",case=False,na=False):\n",
    "    #         # response_plausible = response_plausible + f\" {row['COMMENTS'].str.strip()}\"\n",
    "    #     # Check if 'COMMENTS' does not contain \"P value\" or \"correlation\"\n",
    "    #     if pd.notna(row['COMMENTS']) and not re.search(\"P value|correlation\", row['COMMENTS'], flags=re.IGNORECASE):\n",
    "    #         response_plausible += f\" {row['COMMENTS'].strip()}\"    \n",
    "    #     if get_interesting:\n",
    "    #         results.append( {\"role\": \"user\", \"content\":prompt_interesting})\n",
    "    #         results.append( {\"role\": \"assistant\", \"content\":response_interesting})\n",
    "    #     if get_plausible:\n",
    "    #         results.append( {\"role\": \"user\", \"content\":prompt_plausible})\n",
    "    #         results.append( {\"role\": \"assistant\", \"content\":response_plausible})\n",
    "    # return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1688544c1ff353",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_prompts,plausible_prompts = get_examples(data,target = \"Cholelithiasis OR Gallstones OR Gallbladder disease OR cholecystitis\")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8683b067e1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# novel_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c4ed08ffd9ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# novel_res = []\n",
    "# for i in novel_prompts[0:5]:\n",
    "#     novel_res.append(llm(i, max_tokens=64)['choices'][0]['text'])\n",
    "# novel_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56650e0d1f5301",
   "metadata": {},
   "source": [
    "### Let's try a naive embedding + train a model on that\n",
    "* MTEB sota lb are mostly instruct tuned embedder oriented. Hope it won't mess this up.\n",
    "* Could use the llama models for text gen, but for a pure number - maybe easier to get embeds (faster than finetuning)\n",
    "\n",
    "* https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct\n",
    "    * Lots of files?\n",
    "* https://huggingface.co/bijaygurung/stella_en_400M_v5\n",
    "    * Smaller model. More instruct tuning seemingly?  \n",
    "* https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "\n",
    "Could try SetFit finetuning? (Few shot learning)\n",
    "* https://huggingface.co/blog/setfit\n",
    "* https://huggingface.co/docs/setfit/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4845fa95a20e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# ## https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct\n",
    "# model = SentenceTransformer(\"Alibaba-NLP/gte-Qwen2-7B-instruct\", trust_remote_code=True ) # enabled originally\n",
    "# # In case you want to reduce the maximum length:\n",
    "# model.max_seq_length = 4096#8192\n",
    "\n",
    "# queries = [\n",
    "#     \"how much protein should a female eat\",\n",
    "#     \"summit define\",\n",
    "# ]\n",
    "# documents = [\n",
    "#     \"As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "#     \"Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\",\n",
    "# ]\n",
    "\n",
    "# query_embeddings = model.encode(queries, prompt_name=\"query\")\n",
    "# document_embeddings = model.encode(documents)\n",
    "\n",
    "# scores = (query_embeddings @ document_embeddings.T) * 100\n",
    "# print(scores.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189042d32bb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # This model supports two prompts: \"s2p_query\" and \"s2s_query\" for sentence-to-passage and sentence-to-sentence tasks, respectively.\n",
    "# # They are defined in `config_sentence_transformers.json`\n",
    "# query_prompt_name = \"s2p_query\"\n",
    "# queries = [\n",
    "#     \"What are some ways to reduce stress?\",\n",
    "#     \"What are the benefits of drinking green tea?\",\n",
    "# ]\n",
    "# # docs do not need any prompts\n",
    "# docs = [\n",
    "#     \"There are many effective ways to reduce stress. Some common techniques include deep breathing, meditation, and physical activity. Engaging in hobbies, spending time in nature, and connecting with loved ones can also help alleviate stress. Additionally, setting boundaries, practicing self-care, and learning to say no can prevent stress from building up.\",\n",
    "#     \"Green tea has been consumed for centuries and is known for its potential health benefits. It contains antioxidants that may help protect the body against damage caused by free radicals. Regular consumption of green tea has been associated with improved heart health, enhanced cognitive function, and a reduced risk of certain types of cancer. The polyphenols in green tea may also have anti-inflammatory and weight loss properties.\",\n",
    "# ]\n",
    "\n",
    "# # ÔºÅThe default dimension is 1024, if you need other dimensions, please clone the model and modify `modules.json` to replace `2_Dense_1024` with another dimension, e.g. `2_Dense_256` or `2_Dense_8192` !\n",
    "# # on gpu\n",
    "# model = SentenceTransformer(\"dunzhang/stella_en_400M_v5\", trust_remote_code=True)#.cuda() # needs xformers\n",
    "# # you can also use this model without the features of `use_memory_efficient_attention` and `unpad_inputs`. It can be worked in CPU.\n",
    "# # model = SentenceTransformer(\n",
    "# #     \"dunzhang/stella_en_400M_v5\",\n",
    "# #     trust_remote_code=True,\n",
    "# #     device=\"cpu\",\n",
    "# #     config_kwargs={\"use_memory_efficient_attention\": False, \"unpad_inputs\": False}\n",
    "# # )\n",
    "# query_embeddings = model.encode(queries, prompt_name=query_prompt_name)\n",
    "# doc_embeddings = model.encode(docs)\n",
    "# print(query_embeddings.shape, doc_embeddings.shape)\n",
    "# # (2, 1024) (2, 1024)\n",
    "# similarities = model.similarity(query_embeddings, doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b5d633faff3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\", trust_remote_code=True)#.cuda()\n",
    "model = SentenceTransformer(\"BAAI/bge-base-en-v1.5\", trust_remote_code=True) #  53,66 auc (Without features)\n",
    "# model = SentenceTransformer(\"FremyCompany/BioLORD-2023\")\n",
    "\n",
    "# model = SentenceTransformer(\"Alibaba-NLP/gte-large-en-v1.5\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704dda7a42000056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49440b258aed642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = model.encode(novel_prompts)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6425785ce89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.select_dtypes([\"number\"])) # Lacks mos useful metadata like path length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d29f84845d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.hstack([X,data.select_dtypes([\"number\"]).fillna(-0.1)]) ## Massively boost performance\n",
    "X = np.hstack([X,data.select_dtypes([\"number\"])]) #keep nans - if rf\n",
    "# from 53,67 (w'BAAI/bge-base-en-v1.5) to 61, 74 auc  (with basic min feats)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86b245e50b7188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LogisticRegressionCV()\n",
    "# clf = LogisticRegression()\n",
    "# clf = make_pipeline(StandardScaler(),SimpleImputer(add_indicator=True), LogisticRegression())\n",
    "clf = RandomForestClassifier(500, min_samples_split=4, min_samples_leaf=3,ccp_alpha=0.015) ## 60, 66 (with extra feats; max)\n",
    "# clf = KNeighborsClassifier().8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317d25959057624",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Novel\")\n",
    "y_novel = data[\"Interesting?\"].astype(int)\n",
    "y_novel_pred = cross_val_predict(clf,X,y_novel)\n",
    "y_proba = cross_val_predict(clf,X,y_novel,method=\"predict_proba\")[:,1]\n",
    "print(classification_report(y_novel,y_novel_pred))\n",
    "print(\"rocAUC\",round(roc_auc_score(y_novel,y_proba),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1331b66eb376b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions( y_novel,y_proba,plot_chance_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df351d961e970f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plausible\")\n",
    "y_plausible = data[\"Plausible/Makes Sense?\"].astype(int)\n",
    "y_plausible_pred = cross_val_predict(clf,X,y_plausible)\n",
    "print(classification_report(y_plausible,y_plausible_pred))\n",
    "y_proba = cross_val_predict(clf,X,y_novel,method=\"predict_proba\")[:,1]\n",
    "\n",
    "print(\"rocAUC\",round(roc_auc_score(y_plausible,y_proba),3))\n",
    "RocCurveDisplay.from_predictions( y_plausible,y_proba,plot_chance_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831243c4034fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
