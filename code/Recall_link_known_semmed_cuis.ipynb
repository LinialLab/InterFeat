{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1790e6e-bbf4-46c0-816f-de2c33aebb87",
   "metadata": {},
   "source": [
    "I modify and exclude various code chunks from the original code here (e.g removing extra semantic filtering of candidates, graph features).\n",
    "* Modify  to get multiple entities per text, not just first : `get_multiple_nel` instead of `test_nel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "789089a4-6cf2-4503-b8ca-b54efe3e85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set the environment variable\n",
    "# os.environ['NX_CUGRAPH_AUTOCONFIG'] = 'True'\n",
    "# %env NX_CUGRAPH_AUTOCONFIG=True\n",
    "## make networkx use gpu\n",
    "## https://developer.nvidia.com/blog/networkx-introduces-zero-code-change-acceleration-using-nvidia-cugraph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3a2debb73bd338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T16:12:12.543212Z",
     "start_time": "2024-12-02T16:12:10.723220Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import get_ipython\n",
    "from IPython.core.display_functions import display\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "\n",
    "## scispacy, medspacy, medcat, quickumls, semrep...\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "import spacy\n",
    "import scispacy\n",
    "from itertools import compress\n",
    "from scispacy.linking import EntityLinker\n",
    "from scispacy.abbreviation import AbbreviationDetector ## https://github.com/allenai/scispacy?tab=readme-ov-file#example-usage\n",
    "\n",
    "import sys, os ## append parent path to dir to allow import\n",
    "parent_directory = os.path.abspath('..')\n",
    "sys.path.append(parent_directory)\n",
    "from util import get_sentence_pairs_similarity, wrangle_df_icu, anti_join_df,test_nel,get_multiple_nel,link_kg_concepts_slim\n",
    "from util import *\n",
    "import string\n",
    "rem = string.punctuation\n",
    "punct_pattern = r\"[{}]\".format(rem)\n",
    "# get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "# get_ipython().run_line_magic('autoreload', '2')\n",
    "from configs import * #config_gall\n",
    "import logging\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore', message=\".*UserWarning*.\")\n",
    "# warnings.filterwarnings('ignore', message='.*Duplicate section*.')\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)  # Catch UserWarnings more broadly\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The component 'matcher' does not have any patterns defined.*\")\n",
    "\n",
    "# Set up logger to suppress spaCy's warnings\n",
    "logger = logging.getLogger(\"spacy\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c44d0a-8522-4b67-9f63-cf180314bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffYear = 2012\n",
    "FastRun = False#True\n",
    "SAVE = False # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f48739-2f25-4746-becc-d60ed20a6ce1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def test_nel(text,nlp,do_print=False):\n",
    "#     doc = nlp(text)\n",
    "#     # Let's look at a random entity!\n",
    "#     if do_print: print(\"All ents\", doc.ents)\n",
    "#     ## broken code snippet : https://github.com/allenai/scispacy/issues/355\n",
    "#     for e in doc.ents:\n",
    "#         if e._.kb_ents:\n",
    "#             cui = e._.kb_ents[0][0]\n",
    "#             print(e, cui)\n",
    "\n",
    "#     if do_print:print(\"\\n--------------------------\\n\")\n",
    "#     entity = doc.ents[0]\n",
    "#     if do_print:print(\"Name: \", entity)\n",
    "\n",
    "#     # Each entity is linked to UMLS with a score\n",
    "#     # (currently just char-3gram matching).\n",
    "#     if do_print:\n",
    "#         linker = nlp.get_pipe(\"scispacy_linker\")\n",
    "#         for umls_ent in entity._.kb_ents:\n",
    "#             print(linker.kb.cui_to_entity[umls_ent[0]])\n",
    "#     return entity\n",
    "\n",
    "# def get_multiple_nel(text, nlp,do_print=False):\n",
    "#     \"modified to get multiple entities , not just first\"\n",
    "#     doc = nlp(text)\n",
    "#     if do_print:print(\"All entities:\", doc.ents)\n",
    "    \n",
    "#     entities_with_cuis = []\n",
    "    \n",
    "#     for e in doc.ents:\n",
    "#         if e._.kb_ents:\n",
    "#             cuis = [cui[0] for cui in e._.kb_ents]\n",
    "#             if do_print:print(f\"Entity: {e}, CUIs: {cuis}\")\n",
    "#             entities_with_cuis.append({\n",
    "#                 'entity': e,\n",
    "#                 'cuis': cuis\n",
    "#             })\n",
    "    \n",
    "#     if do_print:\n",
    "#         print(\"\\n--------------------------\\n\")\n",
    "#         linker = nlp.get_pipe(\"scispacy_linker\")\n",
    "#         for ent in entities_with_cuis:\n",
    "#             print(f\"Details for Entity: {ent['entity']}\")\n",
    "#             for umls_ent in ent['cuis']:\n",
    "#                 print(linker.kb.cui_to_entity[umls_ent])\n",
    "    \n",
    "#     return entities_with_cuis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T16:12:12.544309Z",
     "start_time": "2024-12-02T16:12:12.544259Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ## slim in that some parts disabled/commented out (semantic similarity filter etc'): renamed from link_kg_concepts       \n",
    "# def link_kg_concepts_slim(FEATURES_REPORT_PATH, CANDIDATE_NOVEL_CUIS_FILEPATH, TARGET_NAME, additional_target_cui_terms_list=[], SAVE_OUTPUTS = False, MIN_EVIDENCE_FILTER = 1,\n",
    "#                      REMOVE_CUI_TERMS_LIST=['Prieto syndrome', \"Polarized Reflectance Spectroscopy\",\n",
    "#                                             # mistaken extraction from PRS - drop it for now for cleanliness\n",
    "#                                             'Standard (qualifier)', 'Standard base excess calculation technique',\n",
    "#                                             'Standard of Care', 'Spatial Frequency', 'Disease',\n",
    "#                                             'Statistical Frequency', 'Kind of quantity - Frequency', 'Concentration measurement',\n",
    "#                                             'Concentration measurement', 'Illness (finding)', 'Concentration Ratio',\n",
    "#                                             \"Special\", \"ActInformationPrivacyReason <operations>\", \"Left sided\", \"Left\", \"Right\",\n",
    "#                                             \"Table Cell Horizontal Align - left\", \"Query Quantity Unit - Records\", \"Up\",\n",
    "#                                             \"Qualification\",\n",
    "#                                             \"Visit\", \"Total\", \"Participant\", \"Overall\", \"Right sided\", \"Left sided\",\n",
    "#                                             \"Take\", \"Percent (qualifier value)\",\"Population Group\",\n",
    "#                                             \"Diagnosis\",\"Coding\",\"Code\",\n",
    "#                                             \"Average\" , \"Comparison\" , \"Lost\" , \"Yes - Presence findings\", \n",
    "#                                             \"Pharmaceutical Preparations\",\"Physicians\",\"Mother (person)\",\"Father (person)\",\"Severe (severity modifier)\",\n",
    "#                                             ]\n",
    "#                      , input_kg_path=\"../../SemMed/predications.parquet\", EXCLUDE_TUIS_LIST = [\"T079\", \"T093\", \"T094\", \"T095\", \"T170\", \"T204\", \"T201\", \"T065\",\n",
    "#                          \"T078\", ], sem_similarity_threshhold_score=0.12, # 0.15\n",
    "#                      # top_cutoff_simMin = 0.39,top_cutoff_kgHit = 2,\n",
    "#                      FAST=False,\n",
    "#                     return_df=True):\n",
    "#     # global nlp, df_kg_sep, df_hits, G\n",
    "#     global df_kg_sep, df_hits ## maybe disable this..\n",
    "\n",
    "#     # ### Load processed semmed db\n",
    "#     # * ths version has 1 row per triple.\n",
    "#     # * `Count` is the number of unique PMIDs the triple has appeared in\n",
    "#     df_kg = pd.read_parquet(input_kg_path)\n",
    "\n",
    "#     # ### Filtered version\n",
    "\n",
    "#     df_kg = df_kg.loc[df_kg[\"pair_counts\"] >= MIN_EVIDENCE_FILTER].reset_index(drop=True).copy()\n",
    "#     df_kg.drop(columns=[\"pair_counts\",\"counts\"], inplace=True, errors=\"ignore\")\n",
    "#     print(\"After filtering KG min count\")\n",
    "#     for c in df_kg.select_dtypes(\"category\").columns:\n",
    "#         # remove unobserved categories, in new filtered data\n",
    "#         df_kg[c] = df_kg[c].cat.remove_unused_categories()\n",
    "#     print(df_kg.shape[0])  # 4M\n",
    "\n",
    "#     # # !pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_scibert-0.5.4.tar.gz\n",
    "#     # # !pip install 'spacy[transformers]'\n",
    "#     # ```\n",
    "#     # there's also lg, and transformer based\n",
    "#     if FAST:\n",
    "#         nlp = spacy.load(\"en_core_sci_sm\")\n",
    "#     else:\n",
    "#         nlp = spacy.load(\"en_core_sci_lg\")\n",
    "#         # nlp = spacy.load(\"en_core_sci_scibert\") # error in later spacy version?\n",
    "    \n",
    "#     # This line takes a while, because we have to download ~1GB of data\n",
    "#     # and load a large JSON file (the knowledge base). \n",
    "    \n",
    "#     # Add the abbreviation pipe to the spacy pipeline. (if using resolve_abbreviations )\n",
    "#     nlp.add_pipe(\"abbreviation_detector\")\n",
    "#     nlp.add_pipe(\"scispacy_linker\",\n",
    "#                  config={\"resolve_abbreviations\": True,\n",
    "#                          \"linker_name\": \"umls\",\n",
    "#                          \"max_entities_per_mention\": 2  # 3, #6, #4, #5\n",
    "#                      , \"threshold\": 0.82  ## default is 0.8, paper mentions 0.99 as thresh\n",
    "#                          })\n",
    "\n",
    "#     print(\"TARGET_NAME (For Entity-KG linking\", TARGET_NAME)\n",
    "#     # new func\n",
    "#     # entity = get_multiple_nel(TARGET_NAME,nlp=nlp)\n",
    "#     entity = test_nel(TARGET_NAME,nlp=nlp)\n",
    "#     # #### Target terms - may manually change\n",
    "#     ## list of extracted CUIs meaning sepsis. Note that not all correct even here and with threshhold\n",
    "#     list_target_cuis = [i[0] for i in entity._.kb_ents]\n",
    "#     if len(additional_target_cui_terms_list) > 0:\n",
    "#         list_target_cuis = list(set(list_target_cuis + additional_target_cui_terms_list))\n",
    "#     print(\"list_target_cuis\",list_target_cuis)\n",
    "#     # #### get subset of KG with target in pairs\n",
    "#     # (not 100% sure if ideal, but will save time when comparing features )\n",
    "#     df_kg_sep = df_kg.loc[(df_kg[\"SUBJECT_CUI\"].isin(list_target_cuis)) | (df_kg[\"OBJECT_CUI\"].isin(list_target_cuis))].copy()\n",
    "#     df_kg_sep.drop_duplicates(['SUBJECT_CUI', 'SUBJECT_NAME', 'OBJECT_CUI', 'OBJECT_NAME'],\n",
    "#                               inplace=True)  # ignore predicate type for this filter table\n",
    "#     # In[28]:\n",
    "#     ## sample set of terms from gallstone prediction + filtered\n",
    "#     icu_feature_terms = pd.read_csv(FEATURES_REPORT_PATH)\n",
    "\n",
    "#     if FAST:\n",
    "#         icu_feature_terms = icu_feature_terms.loc[icu_feature_terms[\"feature_importance\"] > 0].head(25)\n",
    "#     icu_feature_terms = wrangle_df_icu(icu_feature_terms)\n",
    "#     ##############################################################\n",
    "#     ##ORIG code deeted,  , single etity per text - deleted\n",
    "#     ##...\n",
    "#     ##############################################################\n",
    "#     ## slt/new - for multiple entities per text\n",
    "    \n",
    "#     # Initialize lists to collect data\n",
    "#     novel_cols_candidates_names = []\n",
    "#     no_entities_list = []\n",
    "#     novel_candidate_cuis = []\n",
    "#     novel_candidate_cuis_nomenclatures = []\n",
    "#     TUIs_list = []\n",
    "#     list_cui_kg_hits = []\n",
    "#     list_cui_definitions = []\n",
    "    \n",
    "#     # Iterate over each feature name\n",
    "#     for f in icu_feature_terms[\"name\"]:\n",
    "#         doc = nlp(f)\n",
    "#         linker = nlp.get_pipe(\"scispacy_linker\")\n",
    "        \n",
    "#         # Check if any entities are found in the feature name\n",
    "#         if doc.ents:\n",
    "#             # Flag to check if at least one CUI passes the TUI filter\n",
    "#             feature_has_valid_cui = False\n",
    "            \n",
    "#             # Iterate over all entities in the document\n",
    "#             for entity in doc.ents:\n",
    "#                 # Extract all CUIs for the current entity\n",
    "#                 list_feature_cuis = [cui[0] for cui in entity._.kb_ents] if entity._.kb_ents else []\n",
    "                \n",
    "#                 if not list_feature_cuis:\n",
    "#                     continue  # Skip entities without CUIs\n",
    "                \n",
    "#                 # Apply TUI filter to exclude certain CUIs\n",
    "#                 tui_filter_mask = [\n",
    "#                     linker.kb.cui_to_entity[c][3][0] not in EXCLUDE_TUIS_LIST \n",
    "#                     for c in list_feature_cuis\n",
    "#                 ]\n",
    "#                 filtered_cuis = list(compress(list_feature_cuis, tui_filter_mask))\n",
    "                \n",
    "#                 # If no CUIs pass the TUI filter, skip to the next entity\n",
    "#                 if not filtered_cuis:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Mark that this feature has at least one valid CUI\n",
    "#                 feature_has_valid_cui = True\n",
    "                \n",
    "#                 # Extract nomenclatures for the filtered CUIs\n",
    "#                 list_cuis_nomenclatures = [\n",
    "#                     linker.kb.cui_to_entity[c][1] for c in filtered_cuis\n",
    "#                 ]\n",
    "                \n",
    "#                 # Append TUIs for the filtered CUIs\n",
    "#                 TUIs_list.extend([linker.kb.cui_to_entity[c][3][0] for c in filtered_cuis])\n",
    "                \n",
    "#                 # Filter the knowledge graph for related CUIs\n",
    "#                 df_related = df_kg_sep.loc[\n",
    "#                     df_kg_sep[\"SUBJECT_CUI\"].isin(filtered_cuis) | \n",
    "#                     df_kg_sep[\"OBJECT_CUI\"].isin(filtered_cuis)\n",
    "#                 ]\n",
    "                \n",
    "#                 # Iterate over each filtered CUI\n",
    "#                 for cui in filtered_cuis:\n",
    "#                     # Count KG hits for the current CUI\n",
    "#                     ## add .loc\n",
    "#                     num_kg_hits = df_related.loc[\n",
    "#                         (df_kg_sep[\"SUBJECT_CUI\"] == cui) | \n",
    "#                         (df_related[\"OBJECT_CUI\"] == cui)\n",
    "#                     ].shape[0]\n",
    "#                     list_cui_kg_hits.append(num_kg_hits)\n",
    "                    \n",
    "#                     # Collect definitions and synonyms for the current CUI\n",
    "#                     cui_definition = linker.kb.cui_to_entity[cui][4]\n",
    "#                     cui_def_text = f\"{linker.kb.cui_to_entity[cui][1]}. {cui_definition}\" if cui_definition else linker.kb.cui_to_entity[cui][1]\n",
    "#                     list_cui_definitions.append(cui_def_text)\n",
    "                \n",
    "#                 # Extend lists with the current feature name and associated CUIs\n",
    "#                 novel_cols_candidates_names.extend([f] * len(filtered_cuis))\n",
    "#                 novel_candidate_cuis.extend(filtered_cuis)\n",
    "#                 novel_candidate_cuis_nomenclatures.extend(list_cuis_nomenclatures)\n",
    "            \n",
    "#             # If no valid CUIs were found for any entity in the feature, add to no_entities_list\n",
    "#             if not feature_has_valid_cui:\n",
    "#                 no_entities_list.append(f)\n",
    "#         else:\n",
    "#             # If no entities are found in the feature name, add to no_entities_list\n",
    "#             no_entities_list.append(f)\n",
    "    \n",
    "#     # After processing all feature names, remove duplicates from no_entities_list\n",
    "#     no_entities_list = list(set(no_entities_list))\n",
    "#     print(f\"{len(no_entities_list)}:\\n No Entity feats: {no_entities_list}\")\n",
    "    \n",
    "#     # Create the DataFrame with collected data\n",
    "#     df_hits = pd.DataFrame({\n",
    "#         \"feature_name\": novel_cols_candidates_names,\n",
    "#         \"cui\": novel_candidate_cuis,\n",
    "#         \"cui_nomenclature\": novel_candidate_cuis_nomenclatures,\n",
    "#         \"cui_def\": list_cui_definitions,\n",
    "#         \"KG_Hits\": list_cui_kg_hits,\n",
    "#         \"TUI\": TUIs_list\n",
    "#     }).drop_duplicates()\n",
    "\n",
    "#     ##############################################################\n",
    "#     ## merge with icu_feature_terms[[\"raw_name\",\"name\"]]\n",
    "#     s1 = df_hits.shape[0]\n",
    "#     df_hits = df_hits.loc[~df_hits[\"cui_nomenclature\"].isin(REMOVE_CUI_TERMS_LIST)]\n",
    "#     print(s1 - df_hits.shape[0], \"Rows of unwanted cuis dropped\")\n",
    "#     for c in list_target_cuis:  ## manually append it hewre with some of the feature vals\n",
    "#         df_hits._append({\"cui\": c, \"feature_name\": \"target\", \"cui_nomenclature\": linker.kb.cui_to_entity[c][1]}, ignore_index=True)\n",
    "#     s1 = df_hits.shape[0]\n",
    "#     # print(s1, \"# rows pre semantic sim filt\")\n",
    "#     ### semantic similarity - heuristic, remove poor scoring pairs (by semantic similarity).\n",
    "#     # ### Note:Could also expandthis with the CUIsdescriptions\n",
    "#     # df_hits = get_sentence_pairs_similarity(df=df_hits, col1=\"cui_nomenclature\", col2=\"feature_name\", filter=True, minFilterValue=0.98 * sem_similarity_threshhold_score\n",
    "#     #                                         , model2Name=None)\n",
    "\n",
    "#     # df_hits.drop(columns=[\"v\", \"kg_hits_robust\"], errors=\"ignore\", inplace=True)\n",
    "#     # \"keep features where at least 1 potentially novel cui = unmatched in known literature-KG:\"\n",
    "#     # # df_hits = df_hits.query(\"feature_level_min_kg_hits==0 & feature_level_avg_kg_hits<0.7\")\n",
    "#     df_hits[\"cui\"] = df_hits[\"cui\"].astype(str)\n",
    "#     df_hits.drop_duplicates(inplace=True)\n",
    "#     print(df_hits[[\"feature_name\", \"cui\"]].nunique())\n",
    "#     print(\"# KG Hits:\")\n",
    "#     print(df_hits.query(\"KG_Hits>0\")[[\"feature_name\", \"cui\"]].nunique())\n",
    "#     ## remove top hits filter \n",
    "#     ###### Add/Keep features that had 0 hits in the KG as additional candidate novels , for next stage of filtering\n",
    "#     # * Add pseudovals for cui\n",
    "\n",
    "#     ## TODO: Add in raw_name\n",
    "#     df_hits = pd.concat([df_hits, pd.DataFrame({\"feature_name\": no_entities_list,\n",
    "#                                                 \"KG_Hits\": [0] * len(no_entities_list),\n",
    "#                                                 \"cui_nomenclature\": [\"\"] * len(no_entities_list),\n",
    "#                                                 \"cui_def\": [\"\"] * len(no_entities_list),\n",
    "#                                                 \"cui\": [\"\"] * len(no_entities_list),\n",
    "#                                                 \"sim_score\": [1] * len(no_entities_list)})], ignore_index=True)\n",
    "    \n",
    "#     ## add:\n",
    "#     \"\"\"Not enough! Doesn't handle empty features being added if present? \"\"\"\n",
    "#     df_hits.drop_duplicates(subset=[\"feature_name\",\"cui\",\"KG_Hits\"],inplace=True) ## added\n",
    "    \n",
    "#     for c in df_hits.select_dtypes(\"number\").columns:\n",
    "#         # print(c)\n",
    "#         df_hits[c] = df_hits[c].fillna(0)\n",
    "\n",
    "#     # #### Rejoin with features metadata\n",
    "#     # * * Warning: missing feature proxies won't be idd correctly may replace the version of column without missings.\n",
    "#     #\n",
    "#     # In[42]:\n",
    "\n",
    "#     # In[43]:\n",
    "#     df_hits = df_hits.merge(icu_feature_terms[['name', 'feature_importance', 'p_val', 'corr', \"MutualInfoTarget\",\n",
    "#                                                'raw_name', # restore\n",
    "#                                                ]].round(3),\n",
    "#                             left_on=[\"feature_name\"], right_on=\"name\", how=\"left\", validate=\"m:1\").drop(columns=[\"name\", \"TUI\"], errors=\"ignore\")\n",
    "\n",
    "#     # ### Very common/reoccurring nomenclatures - may be too broad\n",
    "#     # * could remove these based on counts, tf-idf, percentile distribution.\n",
    "\n",
    "#     print(f\"# {len(no_entities_list)}features with no linked entities in them:\\n\")\n",
    "#     print(len(novel_cols_candidates_names), \"# novel candidate\")\n",
    "    \n",
    "#     # print(f\"{100*(len(novel_cols_candidates_names)/len(icu_feature_terms)):.2f}% candidates novel\")\n",
    "#     # for gallstones - 52% (78) when using TF linker, vs 66% (100) using statistical linker\n",
    "#     # In[58]:\n",
    "#     print(\"novel candidates # CUIS:\", len(novel_candidate_cuis))\n",
    "\n",
    "\n",
    "#     # # #### Add seperate sim score between feature name (+- cui?) and the TARGET\n",
    "#     # # * NOTE! This differs from the OTHER sim_score (which was used for filtering NEL results); this one is more for further\n",
    "#     # # In[38]:\n",
    "#     # df_temp = df_hits[[\"feature_name\", \"cui_nomenclature\"]].copy()  # .head(10) # .drop_duplicates(subset=[\"feature_name\"])\n",
    "#     # df_temp[\"target_name\"] = TARGET_NAME\n",
    "#     # df_hits[\"sim_score_target_feat\"] = get_sentence_pairs_similarity(df=df_temp.copy(), col1=\"target_name\", col2=\"feature_name\", filter=False,\n",
    "#     #                                                                  return_score_only=True)\n",
    "#     # # df_hits[\"sim_score_target_cui\"] = get_sentence_pairs_similarity(df=df_temp.copy(),col1=\"cui_nomenclature\",col2=\"target_name\",filter=False,return_score_only=True)\n",
    "#     # df_hits[\"sim_score_target_cui\"] = get_sentence_pairs_similarity(df=df_temp.copy(), col1=\"target_name\", col2=\"cui_nomenclature\",\n",
    "#     #                                                                 model2Name=None,\n",
    "#     #                                                                 filter=False, return_score_only=True)\n",
    "\n",
    "#     # In[59]:\n",
    "#     for c in list_target_cuis:\n",
    "#         print(linker.kb.cui_to_entity[c][1])\n",
    "\n",
    "#     # ## Graph connectivity metric\n",
    "#     df_path_lengths = get_kg_connections(df_hits, df_kg, list_target_cuis)\n",
    "#     print(df_path_lengths.shape,\"df_path_lengths\")\n",
    "#     print(df_hits.shape, \"df_hits\")\n",
    "#     # In[63]:\n",
    "#     df_hits = df_hits.merge(df_path_lengths.drop(columns=[\"node_degree\"], errors=\"ignore\").drop_duplicates(), on=\"cui\", how=\"left\")\n",
    "\n",
    "#     # ### Save output report\n",
    "#     # * Saves highly filtered (heuristic) candiadtes, eg.g with no kg hits. (+- path length?)\n",
    "#     # In[66]:\n",
    "#     if SAVE_OUTPUTS:\n",
    "#         df_hits[\"cui\"] = df_hits[\"cui\"].astype(str)\n",
    "#         print(CANDIDATE_NOVEL_CUIS_FILEPATH)\n",
    "\n",
    "#     if return_df:\n",
    "#         return df_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df34e96b03553b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T16:12:12.544780Z",
     "start_time": "2024-12-02T16:12:12.544728Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_kg_connections(df_hits, df_kg, list_target_cuis):\n",
    "    # ## Graph connectivity metric\n",
    "    # * Get shortest path (could also get # simplest paths) between source and target, from graph.\n",
    "    # * We'll calculate that only on pairs lacking a direct link to save compute + other tricks.\n",
    "    #\n",
    "    # *    \"shortest_path_length\": Higher is novel\n",
    "    # *    \"simple_path_length\": Lower is novel\n",
    "    # *    \"norm_path_length\": Lower is novel\\\n",
    "    #\n",
    "    df_kg = df_kg.copy()\n",
    "    ## make string to suppress replace warning:\n",
    "    df_kg[\"SUBJECT_CUI\"] = df_kg[\"SUBJECT_CUI\"].astype(str)\n",
    "    df_kg[\"OBJECT_CUI\"] = df_kg[\"OBJECT_CUI\"].astype(str)\n",
    "    df_kg[\"SUBJECT_CUI\"] = df_kg[\"SUBJECT_CUI\"].replace(list_target_cuis, \"y\")\n",
    "    df_kg[\"OBJECT_CUI\"] = df_kg[\"OBJECT_CUI\"].replace(list_target_cuis, \"y\")\n",
    "    G = df_kg[[\"SUBJECT_CUI\", \"OBJECT_CUI\"]].drop_duplicates().copy()\n",
    "    # G[\"SUBJECT_CUI\"] = G[\"SUBJECT_CUI\"].replace(list_target_cuis, \"y\")\n",
    "    # G[\"OBJECT_CUI\"] = G[\"OBJECT_CUI\"].replace(list_target_cuis, \"y\")\n",
    "    G = G.drop_duplicates().reset_index(drop=True)\n",
    "    assert G[\"SUBJECT_CUI\"].value_counts()[\"y\"] > 5\n",
    "    assert G[\"OBJECT_CUI\"].value_counts()[\"y\"] > 5\n",
    "    G.columns = ['source', 'target']\n",
    "    # Create an undirected graph from the DataFrame:\n",
    "    G = nx.from_pandas_edgelist(G, 'source', 'target', create_using=nx.Graph())\n",
    "    ## make directed graph\n",
    "    # G = nx.from_pandas_edgelist(G, 'source', 'target', create_using=nx.DiGraph())  # what about to-from target vs from-to ??\n",
    "    ## drop prefilt of distance 0 cases , because we also want their simple paths\n",
    "    df_temp = df_hits.drop_duplicates(subset=[\"cui\"]).copy()  # .iloc[0:50,0:5]\n",
    "    # # could skip and later readd all the cases with a known direct link to skip their compute time, if a bottleneck\n",
    "    # df_known_cuis_list = df_temp.loc[df_temp[\"KG_Hits\"]>0][[\"cui\"]].reset_index(drop=True).copy()\n",
    "    # df_known_cuis_list[\"short_path_length\"] = 1 # shortest distance in nx - 1 dge\n",
    "    # df_temp = df_temp.loc[df_temp[\"KG_Hits\"]<1].reset_index(drop=True).copy()\n",
    "    candidate_cuis_list = df_temp[\"cui\"].unique()\n",
    "    short_path_length_list = []\n",
    "    # simple_path_length_list = []  ## simple paths part is much slkower!!\n",
    "    # degrees_list = []  # store # out degree of nodes, (could do out degree if using directed graph ) for possible normalizing of simple paths?\n",
    "    for i, c in tqdm(enumerate(candidate_cuis_list), total=len(candidate_cuis_list), desc=\"Calculating Paths\"):\n",
    "        if c in G:\n",
    "            # degrees_list.append(G.degree(c))\n",
    "            try:\n",
    "                # Calculate shortest path length\n",
    "                path_length = nx.shortest_path_length(G, source=c, target=\"y\")\n",
    "                short_path_length_list.append(path_length)\n",
    "            except nx.NetworkXNoPath:\n",
    "                # Handle cases where no path exists\n",
    "                short_path_length_list.append(999)  # Indicate no path (smaller is better)  - float('inf') , or a placeholder large int\n",
    "            # try:\n",
    "            #     simple_path_length = len(list(nx.all_simple_edge_paths(G, source=c, target=\"y\", cutoff=2)))  # can be slow!!\n",
    "            #     simple_path_length_list.append(simple_path_length)\n",
    "            # except:\n",
    "            #     simple_path_length_list.append(0)\n",
    "        else:\n",
    "            # # Handle cases where the candidate node is not in the graph\n",
    "            # print(f\"Node {c} not found in the graph.\")\n",
    "            short_path_length_list.append(99)  # Use  float('inf') None or another marker (0) to indicate missing node\n",
    "            # simple_path_length_list.append(0)\n",
    "            # degrees_list.append(0)\n",
    "    df_path_lengths = pd.DataFrame({\"cui\": candidate_cuis_list,\n",
    "                                    \"shortest_path_length\": short_path_length_list,\n",
    "                                    # \"simple_path_length\": simple_path_length_list,\n",
    "                                    # \"node_degree\": degrees_list\n",
    "                                    }).sort_values(by=[\"shortest_path_length\"], ascending=True).drop_duplicates(subset=[\"cui\"],\n",
    "                                                                                                                keep=\"first\")  # added drop dupes here and sorting\n",
    "    # # lower is more novel\n",
    "    # ## Disable this and it's constituents above\n",
    "    # df_path_lengths[\"norm_path_length\"] = (df_path_lengths[\"simple_path_length\"].div(df_path_lengths[\"node_degree\"]).fillna(0)).round(2)\n",
    "    return df_path_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad2e19929ab24a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## TODO: Add 2d degree distance linkage? +- Sem dist min filter\n",
    "def temporal_kg_concepts_eval(df_hits,df_kg_sep,KG_YEAR_CUTOFF = 2013):\n",
    "    \"\"\"\n",
    "    Foward Temporal eval\n",
    "    ## Check which links/features from our data appear in \"future\" data\n",
    "    * Take KG, split to train/test by time (e.g. 2014 onwards), if a link appears in 2014 onwads and not in earlier , then it is a possible case of a novel detection from our model.\n",
    "    * Need to consider how to filter cuis/features. e.g. overly common cui nomenclatures\n",
    "\n",
    "    :param df_hits:\n",
    "    :param df_kg_sep:\n",
    "    :param KG_YEAR_CUTOFF:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    print(KG_YEAR_CUTOFF,\"KG_YEAR_CUTOFF\")\n",
    "    df_hits[\"cui_count\"] = df_hits.groupby([\"cui\"]).transform(\"size\")\n",
    "    print(df_kg_sep.nunique())\n",
    "\n",
    "    df_kg_past = df_kg_sep.loc[df_kg_sep[\"first_year_pair\"]<KG_YEAR_CUTOFF]\n",
    "    print(\"past\",df_kg_past.shape[0])\n",
    "    df_kg_future = df_kg_sep.loc[df_kg_sep[\"first_year_pair\"]>=KG_YEAR_CUTOFF]\n",
    "    print(\"Future, before filter/antijoin\",df_kg_future.shape[0])\n",
    "\n",
    "\n",
    "    df_kg_future = anti_join_df(left=df_kg_future, right=df_kg_past, key=[\"SUBJECT_CUI\",\"OBJECT_CUI\"])\n",
    "\n",
    "    past_cuis_list = list(set(df_kg_past[\"SUBJECT_CUI\"].unique().tolist() + df_kg_past[\"OBJECT_CUI\"].unique().tolist()))\n",
    "    print(\"# past cuis\",len(past_cuis_list))\n",
    "\n",
    "    future_cuis_list = list(set(df_kg_future[\"SUBJECT_CUI\"].unique().tolist() + df_kg_future[\"OBJECT_CUI\"].unique().tolist()))\n",
    "    print(\"# future cuis\",len(future_cuis_list))\n",
    "    future_cuis_list = [x for x in future_cuis_list if x not in past_cuis_list]\n",
    "    print(\"# future cuis, not in past\",len(future_cuis_list))\n",
    "\n",
    "\n",
    "    # ## Keep only (model) features that appear in the future, not past , of the KG\n",
    "    #\n",
    "    # * Additional possible filter needed: If any cui (perfeature) is a match in PAST data?\n",
    "    #     * Would need to filter out overly common cuis (e.g. \"genetic risk\") in such a case or multiples...\n",
    "    # * Q: Important filter note: Might want to filter by first appearance/year of a specific cui? e.g. to avoid cases where cui was only added after cutoff. This is arguable, as a novelty might legitiamtely be added as a cui after cutoff..\n",
    "\n",
    "    df_hits_future = df_hits.loc[df_hits[\"cui\"].isin(future_cuis_list)].copy()\n",
    "    print(df_hits_future.shape[0], \"# Rows\")\n",
    "    print(\"nunique:\")\n",
    "    # print(df_hits_future.groupby([\"SUBJECT_CUI\",\"OBJECT_CUI\"]).size(), \"# Subj X Obj cui unique Pairs\")\n",
    "    print(df_hits_future.nunique())\n",
    "    print(\"\\nfeature #:\")\n",
    "    print(df_hits_future.raw_name.value_counts().head(11))\n",
    "    print(\"\\ncui #:\")\n",
    "    print(df_hits_future.cui_nomenclature.value_counts().head(11))\n",
    "\n",
    "\n",
    "    # ### Get feature level (vs cui) level matched hits in past and then use that for filtering\n",
    "    # * Will take higher confidence cuis/terms (to reduce noise)\n",
    "    # * We remove very common cuis that are too broad (e.g. \"gene risk\"). Set at 97% quantile (5 in our case for gallstones)\n",
    "\n",
    "    # In[78]:\n",
    "\n",
    "    df_hits_past = df_hits.loc[df_hits[\"cui\"].isin(past_cuis_list)].copy()\n",
    "    print(df_hits_past.shape[0],\"# rows\\n\")\n",
    "    print(df_hits_past.select_dtypes([\"O\",\"category\"]).nunique(),\"\\n\")\n",
    "\n",
    "    ## redo cui count to use past data, avoid future information leak. Note: distribution looks about the same.\n",
    "    df_hits_past[\"cui_count\"] = df_hits_past.groupby([\"cui\"]).transform(\"size\")\n",
    "\n",
    "    # print(df_hits_past[\"cui_count\"].describe(percentiles=[.5,.9,.97]).round(1))\n",
    "    display(df_hits_past.drop_duplicates([\"cui\"])[\"cui_count\"].describe(percentiles=[.5,.9,.95,.97]).round(1)) # avoid double counting cuis\n",
    "    past_cui_count_cutoff = max(df_hits_past.drop_duplicates([\"cui\"])[\"cui_count\"].quantile(0.97),2)\n",
    "    print(\"cui cutoff for past:\",past_cui_count_cutoff)\n",
    "    df_hits_past = df_hits_past.loc[df_hits_past[\"cui_count\"]<past_cui_count_cutoff]\n",
    "    print(\"\\nAfter cui cutoff filter:\\n\")\n",
    "    print(df_hits_past.shape[0],\"# rows\\n\")\n",
    "    print(df_hits_past.select_dtypes([\"O\",\"category\"]).nunique(),\"\\n\")\n",
    "\n",
    "    # ### Get results - # features in future and not in past, out of all utility featues\n",
    "    # * Additional filter - rmeoval of \"common\" cui terms from the future results also (not just past).\n",
    "\n",
    "    # In[80]:\n",
    "\n",
    "    print(f'Out of {df_hits.query(\"KG_Hits>0\")[\"raw_name\"].nunique()} Features with any hit in KG')\n",
    "    # print(df_hits_future[\"raw_name\"].nunique(),\"# future feats pre past filt\")\n",
    "    df_hits_future = df_hits_future.loc[(~df_hits_future[\"cui\"].isin(df_hits_past[\"cui\"])) & (~df_hits_future[\"raw_name\"].isin(df_hits_past[\"raw_name\"]))]\n",
    "    print(df_hits_future[\"raw_name\"].nunique(),\"# future feats after past filt\")\n",
    "\n",
    "\n",
    "    # * Filter out common cuis like with past\n",
    "    # * Use overall count instead of future only count of those cuis\n",
    "    # * This filtering may be excessive?\n",
    "\n",
    "    # In[81]:\n",
    "\n",
    "    df_hits_future = df_hits_future.loc[df_hits_future[\"cui_count\"]<=past_cui_count_cutoff]\n",
    "    print(df_hits_future.drop_duplicates(\"raw_name\").shape[0])\n",
    "    display(df_hits_future.drop_duplicates(\"raw_name\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af53e53a4a711349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     ## gallstones / Cholelithiasis\n",
    "#     config = {\n",
    "#       #   \"FEATURES_REPORT_PATH\":\"../../gallstone_chol_ipw_feature_report.csv\",\n",
    "#       # \"CANDIDATE_NOVEL_CUIS_FILEPATH\":\"../../candidate_novel_cuis_chol.csv\",\n",
    "#         \"FEATURES_REPORT_PATH\": \"gallstone_chol_ipw_feature_report.csv\",\n",
    "#         \"CANDIDATE_NOVEL_CUIS_FILEPATH\": \"candidate_novel_cuis_chol.csv\", # output path\n",
    "#             \"TARGET_NAME\" :\"GALLSTONES, Cholelithiasis\",\n",
    "#             \"additional_target_cui_terms_list\" : [\"C0008325\", \"C0008311\"] }\n",
    "\n",
    "#     df_hits = link_kg_concepts_slim(FEATURES_REPORT_PATH=config[\"FEATURES_REPORT_PATH\"], CANDIDATE_NOVEL_CUIS_FILEPATH=config[\"CANDIDATE_NOVEL_CUIS_FILEPATH\"],\n",
    "#                      TARGET_NAME=config[\"TARGET_NAME\"],additional_target_cui_terms_list=config[\"additional_target_cui_terms_list\"],\n",
    "#                                SAVE_OUTPUTS = False,\n",
    "#                         MIN_EVIDENCE_FILTER=2,\n",
    "#                                FAST=False\n",
    "#                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def59df-96da-4474-a986-831dfd00ea65",
   "metadata": {},
   "source": [
    "#### Prep function for summarizing coverage\n",
    "* how many covered at each stage , and in future\n",
    "* Note - may be differences due to usage of extraction of all NERs here. (More noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b2198a-35cf-4521-a080-511277f2c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall 'spacy[transformers]' -y\n",
    "# !pip install scispacy spacy sentence_transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168ed4e6-a0c6-43f3-b7d5-f27f8c4890df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddofer/anaconda3/envs/Medrag/lib/python3.11/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<scispacy.linking.EntityLinker at 0x7f7de87805d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from configs import *#  config_celiac,config_gall,  config_gout\n",
    "\n",
    "## import from configs\n",
    "\n",
    "if FastRun:\n",
    "    all_configs = [config_eye_occ,config_gall]\n",
    "else:\n",
    "    all_configs = [\n",
    "    config_gall,  config_gout,config_celiac,\n",
    "      config_spine, config_oesophagus, config_heart, config_eye_occ,config_depression\n",
    "              ] \n",
    "config = all_configs[0]\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "# nlp = spacy.load(\"en_core_sci_scibert\")\n",
    "nlp.add_pipe(\"abbreviation_detector\")\n",
    "nlp.add_pipe(\"scispacy_linker\",\n",
    "             config={\"resolve_abbreviations\": True,\n",
    "                     \"linker_name\": \"umls\"\n",
    "                     ,\"max_entities_per_mention\": 3  # 3, #6, #4, #5\n",
    "                 ,\"threshold\": 0.88  ## default is 0.8, paper mentions 0.99 as thresh\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "979101d5-28fb-4095-bc8d-5543c4818200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- \n",
      " Esophageal cancer \n",
      " ------------------------------------------------------------\n",
      "After filtering KG min count\n",
      "12915192\n",
      "TARGET_NAME (For Entity-KG linking Esophageal cancer\n",
      "All ents (Esophageal cancer,)\n",
      "Esophageal cancer C0014859\n",
      "\n",
      "--------------------------\n",
      "\n",
      "Name:  Esophageal cancer\n",
      "CUI: C0014859, Name: Esophageal Neoplasms\n",
      "Definition: Tumors or cancer of the ESOPHAGUS.\n",
      "TUI(s): T191\n",
      "Aliases (abbreviated, total: 39): \n",
      "\t Esophagus Neoplasm, Neoplasm, Esophagus, Esophageal Tumors, Neoplasm, Esophageal, Esophagus Tumor, Tumor of the Esophagus, esophageal tumor, esophagus neoplasm, Neoplasms, Esophagus, Esophagus--Tumors\n",
      "CUI: C0152018, Name: Esophageal carcinoma\n",
      "Definition: A malignant epithelial tumor arising from the esophageal mucosa. Two major histologic types of esophageal carcinoma have been described: squamous cell carcinoma and adenocarcinoma. This type of cancer is associated with excessive ethanol and cigarette usage.\n",
      "TUI(s): T191\n",
      "Aliases (abbreviated, total: 27): \n",
      "\t Esophageal Cancer, Esophageal carcinoma, esophageal carcinoma, carcinoma of oesophagus, CARCINOMA OF OESOPHAGUS, esophagus carcinoma, ESOPHAGUS, CARCINOMA, Esophageal Carcinoma, Esophagus Carcinoma, ESOPHAGEAL CARCINOMA\n",
      "CUI: C0546837, Name: Malignant neoplasm of esophagus\n",
      "Definition: A primary or metastatic malignant neoplasm involving the esophagus.\n",
      "TUI(s): T191\n",
      "Aliases (abbreviated, total: 42): \n",
      "\t Esophageal Cancer, oesophagus cancer, Esophageal cancer, CA - Cancer of esophagus, Malignant Tumor of Esophagus, Malignant Esophagus Tumor, Cancer of esophagus, Malignant neoplasm of oesophagus, NOS, Malignant tumor of esophagus, Malignant Neoplasm of the Esophagus\n",
      "list_target_cuis ['C0014859', 'C0152018', 'C0546837']\n",
      "222 - No Entity feats:['medication aqueous nasal', 'Lipoprotein A Blood biochemistry', 'Myopia diagnosis moderate/low myopia', 'medication doxazosin', 'Mental health conditions ever diagnosed by a professional group depression', 'Arm fat percentage', 'Age emphysema/chronic bronchitis diagnosed infrequent', 'Mental health conditions ever diagnosed by a professional of group', \"Illnesses of siblings 0 Alzheimer's disease/dementia\", 'Z92.2 - Personal history of long-term (current) use of other medicaments', 'Mental health conditions ever diagnosed by a professional disorder ptsd', 'Job code at visit teaching professionals', 'Average total household income before tax Greater than 100,000', '(EOC) epithelial ovarian cancer genetic risk', 'Job code at visit primary', '(non-UK origin) Country of Birth india', 'avMSE', 'Amount of tobacco currently smoked', 'Job code at visit nurses', 'Job code at visit public', 'Job code at visit services', 'Average total household income before tax 18,000 to 30,999', 'medication tablet', 'Eye problems/disorders Cataract|Other serious eye condition', 'Concentration of VLDL Particles', 'medication text', 'Alcohol intake frequency. Once or twice a week', 'Weight change during worst episode of depression', 'medication fish oil', 'Other serious medical condition/disability diagnosed by doctor Yes - you will be asked about this later by an interviewer', 'Illnesses of siblings 0 Chronic bronchitis/emphysema', 'HDL cholesterol Blood biochemistry', 'Average total household income before tax', 'Frequency of friend/family visits Almost daily', 'gastro oesophageal', 'Job code at visit managers and', 'Concentration of Large HDL Particles', 'Number of self-reported non-cancer illnesses', 'Mouth/teeth dental problems Loose teeth|Dentures', 'Weight (p21002)', 'Falls in the last year No falls', 'Concentration of Medium HDL Particles', '(non-UK origin) Country of Birth south africa', 'Illnesses of siblings 3 Chronic bronchitis/emphysema', 'gord', 'Ethnic background Any other white background', 'medication nasal spray', 'Vascular/heart problems diagnosed by doctor High blood pressure', 'Frequency of friend/family visits 2-4 times a week', 'dietary changes in the last 5 years Yes, because of illness', 'Genetic ethnic grouping', 'Mineral and other dietary supplements Glucosamine|Iron', 'Health satisfaction', 'Hip circumference', 'Long-standing illness, disability or infirmity Prefer not to answer', 'Mental health conditions ever diagnosed by a professional none of', 'Concentration of Medium LDL Particles', 'Fed-up feelings', 'medication 600mg chewable', 'Long-term/recurrent antibiotics as child or teenager infrequent', 'Average Diameter for VLDL Particles', 'hiatus', 'Job code at visit vehicle', 'Average Diameter for LDL Particles', 'Frequency of tiredness / lethargy in last 2 weeks Nearly every day', 'Mouth/teeth dental problems Dentures', 'medication atenolol', 'Mental health conditions ever diagnosed by a professional panic', 'Mental health conditions ever diagnosed by a professional depression', 'Overall health rating Excellent', 'Method of diagnosis when first had COVID-19 Confirmed by a positive rapid lateral flow test', 'Mental health conditions ever diagnosed by a professional nerves panic', '(non-UK origin) Country of Birth south', 'Home area population density - urban or rural Scotland - Large Urban Area', 'Average total household income before tax Less than 18,000', 'Peripheral enthesopathies and allied syndromes', 'LDL direct Blood biochemistry', 'Mental health conditions ever diagnosed by a professional anxiety or', 'hypothyroidism myxoedema', 'Weight change during worst episode of depression Lost weight', 'Basophill percentage', 'Age emphysema/chronic bronchitis diagnosed', 'Mental health conditions ever diagnosed by a professional generalized', 'Blood clot, DVT, bronchitis, emphysema, asthma, rhinitis, eczema, allergy diagnosed by doctor Prefer not to answer', 'Cholesterol in Medium VLDL', 'Medication for cholesterol, blood pressure or diabetes Medication Cholesterol lowering medication|Blood pressure medication', 'medication primrose oil', 'Qualifications College or University degree', 'medication free', 'Mental health conditions ever diagnosed by a professional nerves', 'Eosinophill percentage', 'unclassifiable', 'Mental health conditions ever diagnosed by a professional group anxiety', 'Y83.8 - Other surgical procedures', 'Job code at visit', 'Job code at visit managers', 'Ethnic background infrequent', 'Concentration of Very Small VLDL Particles', 'Qualifications College or University degree|A levels/AS levels or equivalent|O levels/GCSEs or equivalent|Other professional qualifications eg: nursing, teaching', 'Mental health conditions ever diagnosed by a professional depression anxiety', 'Allergy/adverse effect of penicillin', '(SCZ) schizophrenia genetic risk', 'Mental health conditions ever diagnosed by a professional of', 'Other serious medical condition/disability diagnosed by doctor', '(HDL) high density lipoprotein cholesterol genetic risk', 'Job code at visit and', 'Cholesterol in Small VLDL', 'Qualifications O levels/GCSEs or equivalent|NVQ or HND or HNC or equivalent|Other professional qualifications eg: nursing, teaching', 'Average total household income before tax 52,000 to 100,000', 'reflux gord', 'Mental health conditions ever diagnosed by a professional any other', '(HBA1C DF) glycated haemoglobin genetic risk', 'Mouth/teeth dental problems Bleeding gums', 'Mental health conditions ever diagnosed by a professional disorder', 'medication glucosamine', 'Mental health conditions ever diagnosed by a professional nerves generalized', 'Mental health conditions ever diagnosed by a professional group', 'Concentration of Very Large HDL Particles', 'medication capsule', 'Eye problems/disorders Diabetes related eye disease', \"K22.7 - Barrett's oesophagus\", 'dietary changes in the last 5 years', 'Blood clot, DVT, bronchitis, emphysema, asthma, rhinitis, eczema, allergy diagnosed by doctor Emphysema/chronic bronchitis', 'Genetic ethnic grouping Caucasian', 'Cholesterol Blood biochemistry', 'Method of diagnosis when first had COVID-19 Obtained via a positive antibody test (blood test) only', 'Average total household income before tax 31,000 to 51,999', 'Falls in the last year Only one fall', 'Job code at visit social', 'Overall health rating Fair', '(non-UK origin) Country of Birth africa', 'Medium and low fat cheese', 'Wheeze or whistling in the chest in last year', 'Pulse wave reflection index', 'Medication for cholesterol, blood pressure or diabetes Medication Blood pressure medication', 'Mental health conditions ever diagnosed by a professional anxiety', 'Alcohol drinker status Current', 'Mental health conditions ever diagnosed by a professional traumatic stress', 'Method of diagnosis when first had COVID-19 Based on strong personal suspicion (without positive test)', 'Concentration of HDL Particles', 'medication garlic product', 'Hearing difficulty/problems', 'Job code at visit fitters', 'Eye problems/disorders Cataract', 'Long-standing illness, disability or infirmity', 'Home area population density - urban or rural Scotland - Other Urban Area', 'Illnesses of mother 0 Chronic bronchitis/emphysema', 'Time spent outdoors in winter', 'arthritis spondylitis', 'medication entry', 'Age cataract diagnosed', 'medication entry unable', 'Medication for cholesterol, blood pressure or diabetes Blood pressure medication', 'F32.9 - Depressive episode, unspecified', 'Medication for cholesterol, blood pressure or diabetes Cholesterol lowering medication|Blood pressure medication', 'Skin colour Light olive', 'Panic attack caused by medical condition, medication, drugs or alcohol Yes, some of them', 'medication free text', 'medication lansoprazole', 'Illnesses of siblings 4 Heart disease', '(EBMDT) estimated bone mineral density t-score genetic risk', 'Vascular/heart problems diagnosed by doctor None of the above', 'Frequency of friend/family visits Prefer not to answer', 'Mental health conditions ever diagnosed by a professional generalized anxiety', 'Cholesterol in Small LDL', 'Mouth/teeth dental problems Mouth ulcers', 'Panic attack caused by medical condition, medication, drugs or alcohol No, never', 'Age diabetes diagnosed', 'Mental health conditions ever diagnosed by a professional panic attacks', 'gastric stomach', 'A09.9 - Gastroenteritis and colitis of unspecified origin', 'Cascot confidence score', 'Mineral and other dietary supplements Glucosamine|Selenium', 'Time spend outdoors in summer', 'Mental health conditions ever diagnosed by a professional attacks', '(LDL SF) low density lipoprotein cholesterol genetic risk', 'Qualifications O levels/GCSEs or equivalent|NVQ or HND or HNC or equivalent', 'Health satisfaction Very happy', 'Tinnitus severity/nuisance', 'Other non-epithelial cancer of skin', '(United Kingdom) Year immigrated to UK infrequent', 'medication adcal 600mg', 'Job code at visit heavy', 'Mouth/teeth dental problems Mouth ulcers|Bleeding gums', 'Doctor diagnosed lung cancer (not mesothelioma)', 'Number of self-reported cancers', 'Frequency of friend/family visits Never or almost never', '(non-UK origin) Country of Birth pakistan', 'medication liquid', '(IOP) intraocular pressure genetic risk', 'Mental health conditions ever diagnosed by a professional phobia', 'Job code at visit drivers', 'Surgery/amputation of toe or leg', 'Number of treatments/medications taken', 'Mean platelet (thrombocyte) volume', 'Weight change during worst episode of depression Stayed about the same or was on a diet', 'Long-term/recurrent antibiotics as child or teenager', 'gord gastric', 'Mental health conditions ever diagnosed by a professional or', 'Basophill count', 'Started insulin within one year diagnosis of diabetes', 'medication glucosamine product', '(United Kingdom) Year immigrated to UK', 'Non-cancer illness code, self-reported |', 'Weight change during worst episode of depression Gained weight', 'Caffeine drink within last hour', 'Contra-indications for spirometry', 'Neuroticism score', 'Cholesterol in Small HDL', 'medication garlic', 'Fluid intelligence score', 'Job code at visit teaching', 'oesophagitis barretts', 'Mental health conditions ever diagnosed by a professional anxiety disorder', 'Mental health conditions ever diagnosed by a professional or nerves', 'Overall health rating Good', '(AAM) age at menopause genetic risk', 'Townsend deprivation index at recruitment', 'Job code at visit maintenance fitters', 'Qualifications College or University degree|A levels/AS levels or equivalent', 'Circulatory disease NEC', 'medication calcium salts']\n",
      "171 Rows of unwanted cuis dropped\n",
      "977 # rows pre semantic sim filt\n",
      "-83 #Rows dropped after similarity filter\n",
      "-26 #Rows dropped after similarity filter\n",
      "26 rows dropped by cui+Definition/feature semantic sim\n",
      "feature_name    336\n",
      "cui             460\n",
      "dtype: int64\n",
      "# KG Hits:\n",
      "feature_name    81\n",
      "cui             46\n",
      "dtype: int64\n",
      "# No KG Hits for feature:\n",
      "feature_name    324\n",
      "cui             453\n",
      "dtype: int64\n",
      "336 # Feats before @1 filter\n",
      "287  Feats left after top 1 filter\n",
      "features with no linked entities in them:\n",
      " ['medication aqueous nasal', 'Lipoprotein A Blood biochemistry', 'Myopia diagnosis moderate/low myopia', 'medication doxazosin', 'Mental health conditions ever diagnosed by a professional group depression', 'Arm fat percentage', 'Age emphysema/chronic bronchitis diagnosed infrequent', 'Mental health conditions ever diagnosed by a professional of group', \"Illnesses of siblings 0 Alzheimer's disease/dementia\", 'Z92.2 - Personal history of long-term (current) use of other medicaments', 'Mental health conditions ever diagnosed by a professional disorder ptsd', 'Job code at visit teaching professionals', 'Average total household income before tax Greater than 100,000', '(EOC) epithelial ovarian cancer genetic risk', 'Job code at visit primary', '(non-UK origin) Country of Birth india', 'avMSE', 'Amount of tobacco currently smoked', 'Job code at visit nurses', 'Job code at visit public', 'Job code at visit services', 'Average total household income before tax 18,000 to 30,999', 'medication tablet', 'Eye problems/disorders Cataract|Other serious eye condition', 'Concentration of VLDL Particles', 'medication text', 'Alcohol intake frequency. Once or twice a week', 'Weight change during worst episode of depression', 'medication fish oil', 'Other serious medical condition/disability diagnosed by doctor Yes - you will be asked about this later by an interviewer', 'Illnesses of siblings 0 Chronic bronchitis/emphysema', 'HDL cholesterol Blood biochemistry', 'Average total household income before tax', 'Frequency of friend/family visits Almost daily', 'gastro oesophageal', 'Job code at visit managers and', 'Concentration of Large HDL Particles', 'Number of self-reported non-cancer illnesses', 'Mouth/teeth dental problems Loose teeth|Dentures', 'Weight (p21002)', 'Falls in the last year No falls', 'Concentration of Medium HDL Particles', '(non-UK origin) Country of Birth south africa', 'Illnesses of siblings 3 Chronic bronchitis/emphysema', 'gord', 'Ethnic background Any other white background', 'medication nasal spray', 'Vascular/heart problems diagnosed by doctor High blood pressure', 'Frequency of friend/family visits 2-4 times a week', 'dietary changes in the last 5 years Yes, because of illness', 'Genetic ethnic grouping', 'Mineral and other dietary supplements Glucosamine|Iron', 'Health satisfaction', 'Hip circumference', 'Long-standing illness, disability or infirmity Prefer not to answer', 'Mental health conditions ever diagnosed by a professional none of', 'Concentration of Medium LDL Particles', 'Fed-up feelings', 'medication 600mg chewable', 'Long-term/recurrent antibiotics as child or teenager infrequent', 'Average Diameter for VLDL Particles', 'hiatus', 'Job code at visit vehicle', 'Average Diameter for LDL Particles', 'Frequency of tiredness / lethargy in last 2 weeks Nearly every day', 'Mouth/teeth dental problems Dentures', 'medication atenolol', 'Mental health conditions ever diagnosed by a professional panic', 'Mental health conditions ever diagnosed by a professional depression', 'Overall health rating Excellent', 'Method of diagnosis when first had COVID-19 Confirmed by a positive rapid lateral flow test', 'Mental health conditions ever diagnosed by a professional nerves panic', '(non-UK origin) Country of Birth south', 'Home area population density - urban or rural Scotland - Large Urban Area', 'Average total household income before tax Less than 18,000', 'Peripheral enthesopathies and allied syndromes', 'LDL direct Blood biochemistry', 'Mental health conditions ever diagnosed by a professional anxiety or', 'hypothyroidism myxoedema', 'Weight change during worst episode of depression Lost weight', 'Basophill percentage', 'Age emphysema/chronic bronchitis diagnosed', 'Mental health conditions ever diagnosed by a professional generalized', 'Blood clot, DVT, bronchitis, emphysema, asthma, rhinitis, eczema, allergy diagnosed by doctor Prefer not to answer', 'Cholesterol in Medium VLDL', 'Medication for cholesterol, blood pressure or diabetes Medication Cholesterol lowering medication|Blood pressure medication', 'medication primrose oil', 'Qualifications College or University degree', 'medication free', 'Mental health conditions ever diagnosed by a professional nerves', 'Eosinophill percentage', 'unclassifiable', 'Mental health conditions ever diagnosed by a professional group anxiety', 'Y83.8 - Other surgical procedures', 'Job code at visit', 'Job code at visit managers', 'Ethnic background infrequent', 'Concentration of Very Small VLDL Particles', 'Qualifications College or University degree|A levels/AS levels or equivalent|O levels/GCSEs or equivalent|Other professional qualifications eg: nursing, teaching', 'Mental health conditions ever diagnosed by a professional depression anxiety', 'Allergy/adverse effect of penicillin', '(SCZ) schizophrenia genetic risk', 'Mental health conditions ever diagnosed by a professional of', 'Other serious medical condition/disability diagnosed by doctor', '(HDL) high density lipoprotein cholesterol genetic risk', 'Job code at visit and', 'Cholesterol in Small VLDL', 'Qualifications O levels/GCSEs or equivalent|NVQ or HND or HNC or equivalent|Other professional qualifications eg: nursing, teaching', 'Average total household income before tax 52,000 to 100,000', 'reflux gord', 'Mental health conditions ever diagnosed by a professional any other', '(HBA1C DF) glycated haemoglobin genetic risk', 'Mouth/teeth dental problems Bleeding gums', 'Mental health conditions ever diagnosed by a professional disorder', 'medication glucosamine', 'Mental health conditions ever diagnosed by a professional nerves generalized', 'Mental health conditions ever diagnosed by a professional group', 'Concentration of Very Large HDL Particles', 'medication capsule', 'Eye problems/disorders Diabetes related eye disease', \"K22.7 - Barrett's oesophagus\", 'dietary changes in the last 5 years', 'Blood clot, DVT, bronchitis, emphysema, asthma, rhinitis, eczema, allergy diagnosed by doctor Emphysema/chronic bronchitis', 'Genetic ethnic grouping Caucasian', 'Cholesterol Blood biochemistry', 'Method of diagnosis when first had COVID-19 Obtained via a positive antibody test (blood test) only', 'Average total household income before tax 31,000 to 51,999', 'Falls in the last year Only one fall', 'Job code at visit social', 'Overall health rating Fair', '(non-UK origin) Country of Birth africa', 'Medium and low fat cheese', 'Wheeze or whistling in the chest in last year', 'Pulse wave reflection index', 'Medication for cholesterol, blood pressure or diabetes Medication Blood pressure medication', 'Mental health conditions ever diagnosed by a professional anxiety', 'Alcohol drinker status Current', 'Mental health conditions ever diagnosed by a professional traumatic stress', 'Method of diagnosis when first had COVID-19 Based on strong personal suspicion (without positive test)', 'Concentration of HDL Particles', 'medication garlic product', 'Hearing difficulty/problems', 'Job code at visit fitters', 'Eye problems/disorders Cataract', 'Long-standing illness, disability or infirmity', 'Home area population density - urban or rural Scotland - Other Urban Area', 'Illnesses of mother 0 Chronic bronchitis/emphysema', 'Time spent outdoors in winter', 'arthritis spondylitis', 'medication entry', 'Age cataract diagnosed', 'medication entry unable', 'Medication for cholesterol, blood pressure or diabetes Blood pressure medication', 'F32.9 - Depressive episode, unspecified', 'Medication for cholesterol, blood pressure or diabetes Cholesterol lowering medication|Blood pressure medication', 'Skin colour Light olive', 'Panic attack caused by medical condition, medication, drugs or alcohol Yes, some of them', 'medication free text', 'medication lansoprazole', 'Illnesses of siblings 4 Heart disease', '(EBMDT) estimated bone mineral density t-score genetic risk', 'Vascular/heart problems diagnosed by doctor None of the above', 'Frequency of friend/family visits Prefer not to answer', 'Mental health conditions ever diagnosed by a professional generalized anxiety', 'Cholesterol in Small LDL', 'Mouth/teeth dental problems Mouth ulcers', 'Panic attack caused by medical condition, medication, drugs or alcohol No, never', 'Age diabetes diagnosed', 'Mental health conditions ever diagnosed by a professional panic attacks', 'gastric stomach', 'A09.9 - Gastroenteritis and colitis of unspecified origin', 'Cascot confidence score', 'Mineral and other dietary supplements Glucosamine|Selenium', 'Time spend outdoors in summer', 'Mental health conditions ever diagnosed by a professional attacks', '(LDL SF) low density lipoprotein cholesterol genetic risk', 'Qualifications O levels/GCSEs or equivalent|NVQ or HND or HNC or equivalent', 'Health satisfaction Very happy', 'Tinnitus severity/nuisance', 'Other non-epithelial cancer of skin', '(United Kingdom) Year immigrated to UK infrequent', 'medication adcal 600mg', 'Job code at visit heavy', 'Mouth/teeth dental problems Mouth ulcers|Bleeding gums', 'Doctor diagnosed lung cancer (not mesothelioma)', 'Number of self-reported cancers', 'Frequency of friend/family visits Never or almost never', '(non-UK origin) Country of Birth pakistan', 'medication liquid', '(IOP) intraocular pressure genetic risk', 'Mental health conditions ever diagnosed by a professional phobia', 'Job code at visit drivers', 'Surgery/amputation of toe or leg', 'Number of treatments/medications taken', 'Mean platelet (thrombocyte) volume', 'Weight change during worst episode of depression Stayed about the same or was on a diet', 'Long-term/recurrent antibiotics as child or teenager', 'gord gastric', 'Mental health conditions ever diagnosed by a professional or', 'Basophill count', 'Started insulin within one year diagnosis of diabetes', 'medication glucosamine product', '(United Kingdom) Year immigrated to UK', 'Non-cancer illness code, self-reported |', 'Weight change during worst episode of depression Gained weight', 'Caffeine drink within last hour', 'Contra-indications for spirometry', 'Neuroticism score', 'Cholesterol in Small HDL', 'medication garlic', 'Fluid intelligence score', 'Job code at visit teaching', 'oesophagitis barretts', 'Mental health conditions ever diagnosed by a professional anxiety disorder', 'Mental health conditions ever diagnosed by a professional or nerves', 'Overall health rating Good', '(AAM) age at menopause genetic risk', 'Townsend deprivation index at recruitment', 'Job code at visit maintenance fitters', 'Qualifications College or University degree|A levels/AS levels or equivalent', 'Circulatory disease NEC', 'medication calcium salts']\n",
      "1171 # novel candidate cols\n",
      "novel candidates # CUIS: 1171\n",
      "Esophageal Neoplasms\n",
      "Esophageal carcinoma\n",
      "Malignant neoplasm of esophagus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Paths: 100%|| 402/402 [04:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 5) df_path_lengths\n",
      "(918, 19) df_hits\n",
      "611 # unique names before cleaning\n",
      "(611, 11) # feats preclean\n",
      "(611, 11) # feats after mini filt and load\n",
      "482 # unique names post-cleaning\n",
      "num_inputFeat: 482 num_covered_feat: 410 num_features_not_covered: 72\n",
      "mean       0.08\n",
      "sum       32.00\n",
      "size     410.00\n",
      "count    410.00\n",
      "Name: KG_Hits, dtype: float64\n",
      "mean_kg_known: 7.8\n",
      "Distance 2 or less: 97.8\n",
      "Distance 1 or less: 7.8\n",
      "df_sub (36 cases, with direct kg hits)\n",
      "feature_name             32\n",
      "cui                      19\n",
      "cui_nomenclature         19\n",
      "cui_def                  19\n",
      "raw_name                 32\n",
      "F.Split-Feature Split    32\n",
      "dtype: int64\n",
      "\n",
      "Esophageal cancer C0014859\n",
      "list_target_cuis ['C0014859', 'C0152018', 'C0546837']\n",
      "joined with dates, df_kg_sep:\n",
      "1367\n",
      "SUBJECT_CUI        1149\n",
      "OBJECT_CUI          219\n",
      "first_year_pair      75\n",
      "dtype: int64\n",
      "---------------------------------------- Esophageal cancer\n",
      "Post cutoff (2012) features' first appearance stats; :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mean     0.31\n",
       "sum     10.00\n",
       "size    32.00\n",
       "Name: post_cutoff, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 5min 25s, sys: 9.16 s, total: 5min 34s\n",
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_results = []\n",
    "for config in all_configs:\n",
    "    results = {}\n",
    "    print(\"--\"*50,\"\\n\", config[\"TARGET_NAME\"],\"\\n\",\"--\"*30)\n",
    "    # df_hits = link_kg_concepts_slim # ORIG run\n",
    "    df_hits = link_kg_concepts(FEATURES_REPORT_PATH=config[\"FEATURES_REPORT_PATH\"], CANDIDATE_NOVEL_CUIS_FILEPATH=config[\"CANDIDATE_NOVEL_CUIS_FILEPATH\"],\n",
    "                 TARGET_NAME=config[\"TARGET_NAME\"],additional_target_cui_terms_list=config[\"additional_target_cui_terms_list\"],\n",
    "                    MIN_EVIDENCE_FILTER=4 if FastRun else 2,\n",
    "                               # FAST=FastRun,\n",
    "                               SAVE_OUTPUTS = False)\n",
    "\n",
    "    icu_feature_terms = pd.read_csv(config[\"FEATURES_REPORT_PATH\"])\n",
    "    # icu_feature_terms = icu_feature_terms.loc[(icu_feature_terms[\"feature_importance\"] > 0) |(icu_feature_terms[\"MutualInfoTarget\"] >= 0.01)|(icu_feature_terms[\"p_val\"] <= 0.05) ]  # filter a bit - optionally\n",
    "    print(icu_feature_terms[\"name\"].nunique(),\"# unique names before cleaning\")\n",
    "    icu_feature_terms = wrangle_df_icu(icu_feature_terms,filter_feat_imp=True)\n",
    "    print(icu_feature_terms[\"name\"].nunique(),\"# unique names post-cleaning\") # considerable drop after cleaning up feature names, missing values, etc'\n",
    "\n",
    "    ## note: Not using raw/cleaned so there may be disparity! can sanity check by looking at \"no features list \" \n",
    "    ## coverage of features with any linked KG entity\n",
    "    num_inputFeat = icu_feature_terms[\"name\"].nunique()\n",
    "    num_covered_feat = df_hits[\"raw_name\"].nunique()\n",
    "    num_features_not_covered = num_inputFeat- num_covered_feat\n",
    "    print(\"num_inputFeat:\",num_inputFeat,\"num_covered_feat:\",num_covered_feat,\"num_features_not_covered:\",num_features_not_covered)\n",
    "    \n",
    "    ## direct link, ignores 1-2 hops:\n",
    "    print((df_hits.groupby(\"raw_name\")[\"KG_Hits\"].max()>0).agg([\"mean\",\"sum\",\"size\",\"count\"]).round(2))\n",
    "    ## % cases/features with a link with targets in KG\n",
    "    mean_kg_known = (100*(df_hits.groupby(\"raw_name\")[\"KG_Hits\"].max()>0).mean()).round(2)\n",
    "    print(\"mean_kg_known:\",mean_kg_known)\n",
    "    \n",
    "    ## inclde 1-2 hops with target  \n",
    "    frac_dist2_linked = (100*(df_hits.groupby(\"raw_name\")[\"shortest_path_length\"].min()<=2).mean()).round(2)\n",
    "    print(\"Distance 2 or less:\",frac_dist2_linked)\n",
    "    ## distance 1/direct only\n",
    "    frac_dist1_linked = (100*(df_hits.groupby(\"raw_name\")[\"shortest_path_length\"].min()<=1).mean()).round(2)\n",
    "    print(\"Distance 1 or less:\",frac_dist1_linked)\n",
    "    \n",
    "    df_sub = df_hits.query(\"(shortest_path_length<=1) & (KG_Hits>0)\").drop_duplicates([\"raw_name\",\"feature_name\",\"cui\"])\n",
    "    print(f\"df_sub ({df_sub.shape[0]} cases, with direct kg hits)\")\n",
    "    print(df_sub.select_dtypes(\"O\").nunique())\n",
    "    # display(df_sub)\n",
    "    print()\n",
    "    TARGET_NAME=config[\"TARGET_NAME\"]\n",
    "    additional_target_cui_terms_list=config[\"additional_target_cui_terms_list\"]\n",
    "    entity = test_nel(TARGET_NAME,nlp=nlp)\n",
    "    # #### Target terms - may manually change\n",
    "    list_target_cuis = [i[0] for i in entity._.kb_ents]\n",
    "    if len(additional_target_cui_terms_list) > 0:\n",
    "        list_target_cuis = list(set(list_target_cuis + additional_target_cui_terms_list))\n",
    "    print(\"list_target_cuis\",list_target_cuis)\n",
    "    df_kg = pd.read_parquet(\"../../SemMed/predications.parquet\",columns=['SUBJECT_CUI',  'OBJECT_CUI', 'first_year_pair'])\n",
    "    df_kg[\"SUBJECT_CUI\"] = df_kg[\"SUBJECT_CUI\"].astype(str) # silence replace deprecation warnings\n",
    "    df_kg[\"OBJECT_CUI\"] = df_kg[\"OBJECT_CUI\"].astype(str)\n",
    "    df_kg[\"SUBJECT_CUI\"] = df_kg[\"SUBJECT_CUI\"].replace(list_target_cuis, \"y\")\n",
    "    df_kg[\"OBJECT_CUI\"] = df_kg[\"OBJECT_CUI\"].replace(list_target_cuis, \"y\")\n",
    "    # df_kg_sep = df_kg.loc[(df_kg[\"SUBJECT_CUI\"].isin(list_target_cuis)) | (df_kg[\"OBJECT_CUI\"].isin(list_target_cuis))].drop_duplicates().copy()\n",
    "    df_kg_sep = df_kg.loc[(df_kg[\"SUBJECT_CUI\"]==\"y\") | (df_kg[\"OBJECT_CUI\"]==\"y\")].drop_duplicates().copy()\n",
    "    # df_related = df_kg_sep[ df_kg_sep[\"SUBJECT_CUI\"].isin(filtered_cuis) |  df_kg_sep[\"OBJECT_CUI\"].isin(filtered_cuis)]\n",
    "    df_kg_sep = df_kg_sep.groupby([\"SUBJECT_CUI\",\"OBJECT_CUI\"],observed=True).min().reset_index()\n",
    "    print(\"joined with dates, df_kg_sep:\")\n",
    "    print(df_kg_sep.shape[0])\n",
    "    print(df_kg_sep.nunique())\n",
    "    \n",
    "    print(\"--\"*20,TARGET_NAME)\n",
    "    df_dist1_times = df_sub.merge(df_kg_sep.set_index(\"SUBJECT_CUI\")[\"first_year_pair\"],\n",
    "                 left_on=\"cui\",right_index=True,\n",
    "                 how=\"left\").merge(df_kg_sep.set_index(\"OBJECT_CUI\")[\"first_year_pair\"],left_on=\"cui\",right_index=True,how=\"left\")\n",
    "    \n",
    "    df_dist1_times[\"first_year_pair\"] = df_dist1_times[\"first_year_pair_x\"].fillna(df_dist1_times[\"first_year_pair_y\"])\n",
    "    df_dist1_times.dropna(subset=[\"first_year_pair\"],axis=0,inplace=True)\n",
    "    \n",
    "    print(f\"Post cutoff ({cutoffYear}) features' first appearance stats; :\")\n",
    "    df_dates = df_dist1_times.groupby(\"raw_name\")[\"first_year_pair\"].min().reset_index().drop_duplicates()\n",
    "    df_dates[\"post_cutoff\"] = (df_dates[\"first_year_pair\"]>cutoffYear).astype(int)\n",
    "    display(df_dates[\"post_cutoff\"].agg([\"mean\",\"sum\",\"size\"]).round(2))\n",
    "    print(\"--\"*40)\n",
    "    # Save results for the current target\n",
    "    results[TARGET_NAME] = {\n",
    "        \"target\":TARGET_NAME,\n",
    "        \"num_unique_input_features\": num_inputFeat,\n",
    "        \"num_features_without_KG_link\": num_features_not_covered, # appears in kg (regardless of target)\n",
    "        \"num_features_with_KG_link\": num_covered_feat,# appears in kg (regardless of target)\n",
    "        \"percent_features_with_KG_link\": mean_kg_known,\n",
    "        \"percent_features_within_1_hop\": frac_dist1_linked,\n",
    "        \"num_features_within_1_hop\":(df_hits.groupby(\"raw_name\")[\"shortest_path_length\"].min()<=1).sum(),\n",
    "        \"percent_features_within_2_hop\": frac_dist2_linked,\n",
    "        \"num_features_within_2_hop\":(df_hits.groupby(\"raw_name\")[\"shortest_path_length\"].min()<=2).sum(),\n",
    "        \"num_cases_post_cutoff\": df_dates[\"post_cutoff\"].sum(),\n",
    "        \"percent_cases_after_cutoff_year\": df_dates[\"post_cutoff\"].mean(),\n",
    "        \"list_of_target_cuis\": list_target_cuis,\n",
    "        \"num_unique_target_cuis\": len(set(list_target_cuis)),\n",
    "        \"df_kg_sep_size\":df_kg_sep.shape[0],\n",
    "        \"frac_postCutoffYear_dist1\":df_dates[\"post_cutoff\"].mean().round(2),\n",
    "        \"sum_postCutoffYear_dist1\":df_dates[\"post_cutoff\"].sum(),\n",
    "        \"count_before_CutoffYear_dist1\":(df_dates[\"post_cutoff\"].size - df_dates[\"post_cutoff\"].sum()),      \n",
    "    }\n",
    "    \n",
    "    # Append results for this target to the all_results list\n",
    "    all_results.append(results[TARGET_NAME])\n",
    "    print(\"--\"*40)\n",
    "\n",
    "# Convert all_results into a DataFrame\n",
    "df_results = pd.DataFrame(all_results).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848fb701-3d30-4775-a09b-d774494af0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca295d27-fd55-4405-a5c4-62eed5e65aa9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ## pre replace name, raw_feature name\n",
    "# %%time\n",
    "# all_results = []\n",
    "# for config in all_configs:\n",
    "#     results = {}\n",
    "#     print(\"--\"*50,\"\\n\", config[\"TARGET_NAME\"],\"\\n\",\"--\"*30)\n",
    "#     df_hits = link_kg_concepts_slim(FEATURES_REPORT_PATH=config[\"FEATURES_REPORT_PATH\"], CANDIDATE_NOVEL_CUIS_FILEPATH=config[\"CANDIDATE_NOVEL_CUIS_FILEPATH\"],\n",
    "#                  TARGET_NAME=config[\"TARGET_NAME\"],additional_target_cui_terms_list=config[\"additional_target_cui_terms_list\"],\n",
    "#                     MIN_EVIDENCE_FILTER=4 if FastRun else 2,\n",
    "#                                FAST=FastRun, SAVE_OUTPUTS = False)\n",
    "\n",
    "#     icu_feature_terms = pd.read_csv(config[\"FEATURES_REPORT_PATH\"])\n",
    "#     # icu_feature_terms = icu_feature_terms.loc[(icu_feature_terms[\"feature_importance\"] > 0) |(icu_feature_terms[\"MutualInfoTarget\"] >= 0.01)|(icu_feature_terms[\"p_val\"] <= 0.05) ]  # filter a bit - optionally\n",
    "#     print(icu_feature_terms[\"name\"].nunique(),\"# unique names before cleaning\")\n",
    "#     icu_feature_terms = wrangle_df_icu(icu_feature_terms,filter_feat_imp=True)\n",
    "#     print(icu_feature_terms[\"name\"].nunique(),\"# unique names post-cleaning\") # considerable drop after cleaning up feature names, missing values, etc'\n",
    "\n",
    "#     ## note: Not using raw/cleaned so there may be disparity! can sanity check by looking at \"no features list \" \n",
    "#     ## coverage of features with any linked KG entity\n",
    "#     num_inputFeat = icu_feature_terms[\"name\"].nunique()\n",
    "#     num_covered_feat = df_hits[\"feature_name\"].nunique()\n",
    "#     num_features_not_covered = num_inputFeat- num_covered_feat\n",
    "#     print(\"num_inputFeat:\",num_inputFeat,\"num_covered_feat:\",num_covered_feat,\"num_features_not_covered:\",num_features_not_covered)\n",
    "    \n",
    "#     ## direct link, ignores 1-2 hops:\n",
    "#     print((df_hits.groupby(\"feature_name\")[\"KG_Hits\"].max()>0).agg([\"mean\",\"sum\",\"size\",\"count\"]).round(2))\n",
    "#     ## % cases/features with a link with targets in KG\n",
    "#     mean_kg_known = (100*(df_hits.groupby(\"feature_name\")[\"KG_Hits\"].max()>0).mean()).round(2)\n",
    "#     print(\"mean_kg_known:\",mean_kg_known)\n",
    "    \n",
    "#     ## inclde 1-2 hops with target  \n",
    "#     frac_dist2_linked = (100*(df_hits.groupby(\"feature_name\")[\"shortest_path_length\"].min()<=2).mean()).round(2)\n",
    "#     print(\"Distance 2 or less:\",frac_dist2_linked)\n",
    "#     ## distance 1/direct only\n",
    "#     frac_dist1_linked = (100*(df_hits.groupby(\"feature_name\")[\"shortest_path_length\"].min()<=1).mean()).round(2)\n",
    "#     print(\"Distance 1 or less:\",frac_dist1_linked)\n",
    "    \n",
    "#     df_sub = df_hits.query(\"(shortest_path_length<=1) & (KG_Hits>0)\").drop_duplicates([\"raw_name\",\"feature_name\",\"cui\"])\n",
    "#     print(f\"df_sub ({df_sub.shape[0]} cases, with direct kg hits)\")\n",
    "#     print(df_sub.select_dtypes(\"O\").nunique())\n",
    "#     # display(df_sub)\n",
    "#     print()\n",
    "#     TARGET_NAME=config[\"TARGET_NAME\"]\n",
    "#     additional_target_cui_terms_list=config[\"additional_target_cui_terms_list\"]\n",
    "#     entity = test_nel(TARGET_NAME,nlp=nlp)\n",
    "#     # #### Target terms - may manually change\n",
    "#     list_target_cuis = [i[0] for i in entity._.kb_ents]\n",
    "#     if len(additional_target_cui_terms_list) > 0:\n",
    "#         list_target_cuis = list(set(list_target_cuis + additional_target_cui_terms_list))\n",
    "#     print(\"list_target_cuis\",list_target_cuis)\n",
    "#     df_kg = pd.read_parquet(\"../../SemMed/predications.parquet\",columns=['SUBJECT_CUI',  'OBJECT_CUI', 'first_year_pair'])\n",
    "#     df_kg[\"SUBJECT_CUI\"] = df_kg[\"SUBJECT_CUI\"].astype(str) # silence replace deprecation warnings\n",
    "#     df_kg[\"OBJECT_CUI\"] = df_kg[\"OBJECT_CUI\"].astype(str)\n",
    "#     df_kg[\"SUBJECT_CUI\"] = df_kg[\"SUBJECT_CUI\"].replace(list_target_cuis, \"y\")\n",
    "#     df_kg[\"OBJECT_CUI\"] = df_kg[\"OBJECT_CUI\"].replace(list_target_cuis, \"y\")\n",
    "#     # df_kg_sep = df_kg.loc[(df_kg[\"SUBJECT_CUI\"].isin(list_target_cuis)) | (df_kg[\"OBJECT_CUI\"].isin(list_target_cuis))].drop_duplicates().copy()\n",
    "#     df_kg_sep = df_kg.loc[(df_kg[\"SUBJECT_CUI\"]==\"y\") | (df_kg[\"OBJECT_CUI\"]==\"y\")].drop_duplicates().copy()\n",
    "#     # df_related = df_kg_sep[ df_kg_sep[\"SUBJECT_CUI\"].isin(filtered_cuis) |  df_kg_sep[\"OBJECT_CUI\"].isin(filtered_cuis)]\n",
    "#     df_kg_sep = df_kg_sep.groupby([\"SUBJECT_CUI\",\"OBJECT_CUI\"],observed=True).min().reset_index()\n",
    "#     print(\"joined with dates, df_kg_sep:\")\n",
    "#     print(df_kg_sep.shape[0])\n",
    "#     print(df_kg_sep.nunique())\n",
    "    \n",
    "#     print(\"--\"*20,TARGET_NAME)\n",
    "#     df_dist1_times = df_sub.merge(df_kg_sep.set_index(\"SUBJECT_CUI\")[\"first_year_pair\"],\n",
    "#                  left_on=\"cui\",right_index=True,\n",
    "#                  how=\"left\").merge(df_kg_sep.set_index(\"OBJECT_CUI\")[\"first_year_pair\"],left_on=\"cui\",right_index=True,how=\"left\")\n",
    "    \n",
    "#     df_dist1_times[\"first_year_pair\"] = df_dist1_times[\"first_year_pair_x\"].fillna(df_dist1_times[\"first_year_pair_y\"])\n",
    "#     df_dist1_times.dropna(subset=[\"first_year_pair\"],axis=0,inplace=True)\n",
    "    \n",
    "#     print(f\"Post cutoff ({cutoffYear}) features' first appearance stats; :\")\n",
    "#     df_dates = df_dist1_times.groupby(\"raw_name\")[\"first_year_pair\"].min().reset_index().drop_duplicates()\n",
    "#     df_dates[\"post_cutoff\"] = (df_dates[\"first_year_pair\"]>cutoffYear).astype(int)\n",
    "#     display(df_dates[\"post_cutoff\"].agg([\"mean\",\"sum\",\"size\"]).round(2))\n",
    "#     print(\"--\"*40)\n",
    "#     # Save results for the current target\n",
    "#     results[TARGET_NAME] = {\n",
    "#         \"target\":TARGET_NAME,\n",
    "#         \"num_unique_input_features\": num_inputFeat,\n",
    "#         \"num_features_without_KG_link\": num_features_not_covered, # appears in kg (regardless of target)\n",
    "#         \"num_features_with_KG_link\": num_covered_feat,# appears in kg (regardless of target)\n",
    "#         \"percent_features_with_KG_link\": mean_kg_known,\n",
    "#         \"percent_features_within_1_hop\": frac_dist1_linked,\n",
    "#         \"num_features_within_1_hop\":(df_hits.groupby(\"feature_name\")[\"shortest_path_length\"].min()<=1).sum(),\n",
    "#         \"percent_features_within_2_hop\": frac_dist2_linked,\n",
    "#         \"num_features_within_2_hop\":(df_hits.groupby(\"feature_name\")[\"shortest_path_length\"].min()<=2).sum(),\n",
    "#         \"num_cases_post_cutoff\": df_dates[\"post_cutoff\"].sum(),\n",
    "#         \"percent_cases_after_cutoff_year\": df_dates[\"post_cutoff\"].mean(),\n",
    "#         \"list_of_target_cuis\": list_target_cuis,\n",
    "#         \"num_unique_target_cuis\": len(set(list_target_cuis)),\n",
    "#         \"df_kg_sep_size\":df_kg_sep.shape[0],\n",
    "#         \"frac_postCutoffYear_dist1\":df_dates[\"post_cutoff\"].mean().round(2),\n",
    "#         \"sum_postCutoffYear_dist1\":df_dates[\"post_cutoff\"].sum(),\n",
    "#         \"count_before_CutoffYear_dist1\":(df_dates[\"post_cutoff\"].size - df_dates[\"post_cutoff\"].sum()),      \n",
    "#     }\n",
    "    \n",
    "#     # Append results for this target to the all_results list\n",
    "#     all_results.append(results[TARGET_NAME])\n",
    "#     print(\"--\"*40)\n",
    "\n",
    "# # Convert all_results into a DataFrame\n",
    "# df_results = pd.DataFrame(all_results).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "653ade76-502d-4c0f-be2c-bda436a0acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = pd.read_csv(\"./Outputs/Figures/future_recall_coverage_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22bdd4ff-ef08-4d7a-80e8-f8d221a09cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_name</th>\n",
       "      <th>first_year_pair</th>\n",
       "      <th>post_cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wheeze or whistling in the chest in last year_Yes</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Long-term/recurrent antibiotics as child or te...</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Long-term/recurrent antibiotics as child or te...</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Weight change during worst episode of depressi...</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Major dietary changes in the last 5 years_Yes,...</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Salt added to food_Usually</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Salt added to food_Never/rarely</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Salt added to food_Sometimes</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Haemoglobin concentration</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hyperplasia of prostate</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mineral and other dietary supplements_Glucosam...</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mineral and other dietary supplements_Glucosamine</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mineral and other dietary supplements_None of ...</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mineral and other dietary supplements_Glucosam...</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coffee intake</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Reflux esophagitis</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>missing_Chronic airway obstruction</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Doctor diagnosed COPD (chronic obstructive pul...</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Medication for cholesterol, blood pressure or ...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Vitamin D</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Medication for cholesterol, blood pressure or ...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>missing_Pleurisy; pleural effusion</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Method of diagnosis when first had COVID-19_None</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Method of diagnosis when first had COVID-19_Co...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Method of diagnosis when first had COVID-19_Ba...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Concentration of Very Small VLDL Particles</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Most recent bowel cancer screening_6</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Method of diagnosis when first had COVID-19_Co...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             raw_name  first_year_pair  \\\n",
       "29  Wheeze or whistling in the chest in last year_Yes           1953.0   \n",
       "10  Long-term/recurrent antibiotics as child or te...           1957.0   \n",
       "9   Long-term/recurrent antibiotics as child or te...           1957.0   \n",
       "28  Weight change during worst episode of depressi...           1977.0   \n",
       "11  Major dietary changes in the last 5 years_Yes,...           1977.0   \n",
       "26                         Salt added to food_Usually           1982.0   \n",
       "24                    Salt added to food_Never/rarely           1982.0   \n",
       "25                       Salt added to food_Sometimes           1982.0   \n",
       "7                           Haemoglobin concentration           1983.0   \n",
       "8                             Hyperplasia of prostate           1987.0   \n",
       "19  Mineral and other dietary supplements_Glucosam...           1988.0   \n",
       "18  Mineral and other dietary supplements_Glucosamine           1988.0   \n",
       "21  Mineral and other dietary supplements_None of ...           1988.0   \n",
       "20  Mineral and other dietary supplements_Glucosam...           1988.0   \n",
       "4                                       Coffee intake           2000.0   \n",
       "23                                 Reflux esophagitis           2002.0   \n",
       "30                 missing_Chronic airway obstruction           2006.0   \n",
       "6   Doctor diagnosed COPD (chronic obstructive pul...           2006.0   \n",
       "13  Medication for cholesterol, blood pressure or ...           2007.0   \n",
       "27                                          Vitamin D           2007.0   \n",
       "12  Medication for cholesterol, blood pressure or ...           2007.0   \n",
       "31                 missing_Pleurisy; pleural effusion           2010.0   \n",
       "0   Blood clot, DVT, bronchitis, emphysema, asthma...           2020.0   \n",
       "17   Method of diagnosis when first had COVID-19_None           2020.0   \n",
       "16  Method of diagnosis when first had COVID-19_Co...           2020.0   \n",
       "14  Method of diagnosis when first had COVID-19_Ba...           2020.0   \n",
       "5          Concentration of Very Small VLDL Particles           2020.0   \n",
       "3   Blood clot, DVT, bronchitis, emphysema, asthma...           2020.0   \n",
       "2   Blood clot, DVT, bronchitis, emphysema, asthma...           2020.0   \n",
       "1   Blood clot, DVT, bronchitis, emphysema, asthma...           2020.0   \n",
       "22               Most recent bowel cancer screening_6           2020.0   \n",
       "15  Method of diagnosis when first had COVID-19_Co...           2020.0   \n",
       "\n",
       "    post_cutoff  \n",
       "29            0  \n",
       "10            0  \n",
       "9             0  \n",
       "28            0  \n",
       "11            0  \n",
       "26            0  \n",
       "24            0  \n",
       "25            0  \n",
       "7             0  \n",
       "8             0  \n",
       "19            0  \n",
       "18            0  \n",
       "21            0  \n",
       "20            0  \n",
       "4             0  \n",
       "23            0  \n",
       "30            0  \n",
       "6             0  \n",
       "13            0  \n",
       "27            0  \n",
       "12            0  \n",
       "31            0  \n",
       "0             1  \n",
       "17            1  \n",
       "16            1  \n",
       "14            1  \n",
       "5             1  \n",
       "3             1  \n",
       "2             1  \n",
       "1             1  \n",
       "22            1  \n",
       "15            1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dates.drop_duplicates(\"raw_name\").sort_values(\"first_year_pair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aee32216-3c5a-4699-90d2-ddd07713d996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature_name', 'cui', 'cui_nomenclature', 'cui_def', 'KG_Hits',\n",
       "       'sim_score', 'feature_level_min_kg_hits', 'feature_level_sum_kg_hits',\n",
       "       'feature_level_avg_kg_hits', 'feature_importance', 'p_val', 'corr',\n",
       "       'MutualInfoTarget', 'raw_name', 'F.Split-Lift (y==1)',\n",
       "       'F.Split-Support', 'F.Split-Feature Split', 'sim_score_target_feat',\n",
       "       'sim_score_target_cui', 'shortest_path_length', 'simple_path_length',\n",
       "       'norm_path_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[['feature_name', 'cui', 'cui_nomenclature', 'KG_Hits', 'raw_name']].columns#.drop_duplicates(\"cui_nomenclature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df0e9c06-1e24-43f6-84a3-921ccb027d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>cui_nomenclature</th>\n",
       "      <th>KG_Hits</th>\n",
       "      <th>raw_name</th>\n",
       "      <th>first_year_pair</th>\n",
       "      <th>shortest_path_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Method of diagnosis when first had COVID-19</td>\n",
       "      <td>COVID19 (disease)</td>\n",
       "      <td>1</td>\n",
       "      <td>Method of diagnosis when first had COVID-19_None</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Vitamin D</td>\n",
       "      <td>ergocalciferol</td>\n",
       "      <td>1</td>\n",
       "      <td>Vitamin D</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Concentration of Very Small VLDL Particles</td>\n",
       "      <td>Particle</td>\n",
       "      <td>1</td>\n",
       "      <td>Concentration of Very Small VLDL Particles</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Salt added to food Sometimes</td>\n",
       "      <td>Salts</td>\n",
       "      <td>1</td>\n",
       "      <td>Salt added to food_Sometimes</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Method of diagnosis when first had COVID-19 Co...</td>\n",
       "      <td>COVID19 (disease)</td>\n",
       "      <td>1</td>\n",
       "      <td>Method of diagnosis when first had COVID-19_Co...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>Hypersensitivity</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>Hypersensitivity</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>Hypersensitivity</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>Hypersensitivity</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood clot, DVT, bronchitis, emphysema, asthma...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Salt added to food Usually</td>\n",
       "      <td>Salts</td>\n",
       "      <td>1</td>\n",
       "      <td>Salt added to food_Usually</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Salt added to food Never/rarely</td>\n",
       "      <td>Salts</td>\n",
       "      <td>1</td>\n",
       "      <td>Salt added to food_Never/rarely</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Most recent bowel cancer screening</td>\n",
       "      <td>Screening procedure</td>\n",
       "      <td>2</td>\n",
       "      <td>Most recent bowel cancer screening_6</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>Method of diagnosis when first had COVID-19 Ba...</td>\n",
       "      <td>COVID19 (disease)</td>\n",
       "      <td>1</td>\n",
       "      <td>Method of diagnosis when first had COVID-19_Ba...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Method of diagnosis when first had COVID-19 Co...</td>\n",
       "      <td>COVID19 (disease)</td>\n",
       "      <td>1</td>\n",
       "      <td>Method of diagnosis when first had COVID-19_Co...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          feature_name     cui_nomenclature  \\\n",
       "14         Method of diagnosis when first had COVID-19    COVID19 (disease)   \n",
       "39                                           Vitamin D       ergocalciferol   \n",
       "238         Concentration of Very Small VLDL Particles             Particle   \n",
       "370                       Salt added to food Sometimes                Salts   \n",
       "436  Method of diagnosis when first had COVID-19 Co...    COVID19 (disease)   \n",
       "540  Blood clot, DVT, bronchitis, emphysema, asthma...     Hypersensitivity   \n",
       "569  Blood clot, DVT, bronchitis, emphysema, asthma...     Hypersensitivity   \n",
       "579  Blood clot, DVT, bronchitis, emphysema, asthma...     Hypersensitivity   \n",
       "593  Blood clot, DVT, bronchitis, emphysema, asthma...     Hypersensitivity   \n",
       "621                         Salt added to food Usually                Salts   \n",
       "626                    Salt added to food Never/rarely                Salts   \n",
       "666                 Most recent bowel cancer screening  Screening procedure   \n",
       "690  Method of diagnosis when first had COVID-19 Ba...    COVID19 (disease)   \n",
       "692  Method of diagnosis when first had COVID-19 Co...    COVID19 (disease)   \n",
       "\n",
       "     KG_Hits                                           raw_name  \\\n",
       "14         1   Method of diagnosis when first had COVID-19_None   \n",
       "39         1                                          Vitamin D   \n",
       "238        1         Concentration of Very Small VLDL Particles   \n",
       "370        1                       Salt added to food_Sometimes   \n",
       "436        1  Method of diagnosis when first had COVID-19_Co...   \n",
       "540        1  Blood clot, DVT, bronchitis, emphysema, asthma...   \n",
       "569        1  Blood clot, DVT, bronchitis, emphysema, asthma...   \n",
       "579        1  Blood clot, DVT, bronchitis, emphysema, asthma...   \n",
       "593        1  Blood clot, DVT, bronchitis, emphysema, asthma...   \n",
       "621        1                         Salt added to food_Usually   \n",
       "626        1                    Salt added to food_Never/rarely   \n",
       "666        2               Most recent bowel cancer screening_6   \n",
       "690        1  Method of diagnosis when first had COVID-19_Ba...   \n",
       "692        1  Method of diagnosis when first had COVID-19_Co...   \n",
       "\n",
       "     first_year_pair  shortest_path_length  \n",
       "14            2020.0                     1  \n",
       "39            2012.0                     1  \n",
       "238           2020.0                     1  \n",
       "370           2020.0                     1  \n",
       "436           2020.0                     1  \n",
       "540           2020.0                     1  \n",
       "569           2020.0                     1  \n",
       "579           2020.0                     1  \n",
       "593           2020.0                     1  \n",
       "621           2020.0                     1  \n",
       "626           2020.0                     1  \n",
       "666           2020.0                     1  \n",
       "690           2020.0                     1  \n",
       "692           2020.0                     1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dist1_times[['feature_name',  'cui_nomenclature', 'KG_Hits', 'raw_name',\"first_year_pair\",\"shortest_path_length\"]].query(\"first_year_pair>2010\").drop_duplicates(\"feature_name\")#.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b6dfa4c-fd6f-4ce6-a75b-0036d262e42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>num_unique_input_features</th>\n",
       "      <th>num_features_without_KG_link</th>\n",
       "      <th>num_features_with_KG_link</th>\n",
       "      <th>percent_features_with_KG_link</th>\n",
       "      <th>percent_features_within_1_hop</th>\n",
       "      <th>num_features_within_1_hop</th>\n",
       "      <th>percent_features_within_2_hop</th>\n",
       "      <th>num_features_within_2_hop</th>\n",
       "      <th>num_cases_post_cutoff</th>\n",
       "      <th>percent_cases_after_cutoff_year</th>\n",
       "      <th>list_of_target_cuis</th>\n",
       "      <th>num_unique_target_cuis</th>\n",
       "      <th>df_kg_sep_size</th>\n",
       "      <th>frac_postCutoffYear_dist1</th>\n",
       "      <th>sum_postCutoffYear_dist1</th>\n",
       "      <th>count_before_CutoffYear_dist1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Esophageal cancer</td>\n",
       "      <td>482</td>\n",
       "      <td>72</td>\n",
       "      <td>410</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>32</td>\n",
       "      <td>97.8</td>\n",
       "      <td>401</td>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>[C0014859, C0152018, C0546837]</td>\n",
       "      <td>3</td>\n",
       "      <td>1367</td>\n",
       "      <td>0.31</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target  num_unique_input_features  num_features_without_KG_link  \\\n",
       "0  Esophageal cancer                        482                            72   \n",
       "\n",
       "   num_features_with_KG_link  percent_features_with_KG_link  \\\n",
       "0                        410                            7.8   \n",
       "\n",
       "   percent_features_within_1_hop  num_features_within_1_hop  \\\n",
       "0                            7.8                         32   \n",
       "\n",
       "   percent_features_within_2_hop  num_features_within_2_hop  \\\n",
       "0                           97.8                        401   \n",
       "\n",
       "   num_cases_post_cutoff  percent_cases_after_cutoff_year  \\\n",
       "0                     10                             0.31   \n",
       "\n",
       "              list_of_target_cuis  num_unique_target_cuis  df_kg_sep_size  \\\n",
       "0  [C0014859, C0152018, C0546837]                       3            1367   \n",
       "\n",
       "   frac_postCutoffYear_dist1  sum_postCutoffYear_dist1  \\\n",
       "0                       0.31                        10   \n",
       "\n",
       "   count_before_CutoffYear_dist1  \n",
       "0                             22  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c894c185-3d34-4658-82e2-0db24f9a9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    df_results.to_csv(\"./Outputs/Figures/future_recall_coverage_report.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab291e-1aed-43f0-b3b8-42f574794df2",
   "metadata": {},
   "source": [
    "#### Get negative candidates\n",
    "* feat imp\n",
    "* Negative interesting + make fae explanation\n",
    "* maybe check that model didn't find as interesting ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d30af228-51d1-4cfe-955a-d467e9943bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611, 11) # feats preclean\n"
     ]
    }
   ],
   "source": [
    "icu_feature_terms = pd.read_csv(config[\"FEATURES_REPORT_PATH\"])\n",
    "\n",
    "icu_weak  = wrangle_df_icu(icu_feature_terms,filter_feat_imp=False)\n",
    "\n",
    "icu_weak = icu_feature_terms.loc[(icu_weak[\"feature_importance\"]< 0.0001) &(icu_feature_terms[\"MutualInfoTarget\"] < 0.0001)] \n",
    "# icu_weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0af252a9-5d9e-42bb-ac1d-6e54920f82ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_name                 32\n",
       "cui                          19\n",
       "cui_nomenclature             19\n",
       "cui_def                      19\n",
       "KG_Hits                       3\n",
       "sim_score                    35\n",
       "feature_level_min_kg_hits     2\n",
       "feature_level_sum_kg_hits     3\n",
       "feature_level_avg_kg_hits     8\n",
       "feature_importance           17\n",
       "p_val                        24\n",
       "corr                         27\n",
       "MutualInfoTarget             23\n",
       "raw_name                     32\n",
       "F.Split-Lift (y==1)          25\n",
       "F.Split-Support              30\n",
       "F.Split-Feature Split        32\n",
       "sim_score_target_feat        19\n",
       "sim_score_target_cui         21\n",
       "shortest_path_length          1\n",
       "simple_path_length           12\n",
       "norm_path_length             10\n",
       "first_year_pair_x            11\n",
       "first_year_pair_y             5\n",
       "first_year_pair              14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dist1_times.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74761c19-65c2-4bad-950a-1b09dfa1bcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32.000\n",
       "mean      0.312\n",
       "std       0.471\n",
       "min       0.000\n",
       "25%       0.000\n",
       "50%       0.000\n",
       "75%       1.000\n",
       "max       1.000\n",
       "Name: post_cutoff, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dates[\"post_cutoff\"].describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff72c5ae-1db5-483c-b45f-0c9cf91fb8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cui_nomenclature\n",
       "Hypersensitivity                      4\n",
       "Minerals                              4\n",
       "COVID19 (disease)                     4\n",
       "Food                                  3\n",
       "Salts                                 3\n",
       "Chronic Obstructive Airway Disease    2\n",
       "Adolescent (age group)                2\n",
       "Diabetes Mellitus                     2\n",
       "Diet                                  2\n",
       "Coffee                                1\n",
       "Hyperplasia                           1\n",
       "Peptic Esophagitis                    1\n",
       "Pleural effusion disorder             1\n",
       "Particle                              1\n",
       "Hemoglobin                            1\n",
       "Chest                                 1\n",
       "vitamin D                             1\n",
       "ergocalciferol                        1\n",
       "Screening procedure                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub[\"cui_nomenclature\"].value_counts().head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
